{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenNotBen1224/Dive-Into-Deep-Learning/blob/main/chapter_preliminaries/probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2ef73a8",
      "metadata": {
        "id": "c2ef73a8"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "8a66c1f7",
      "metadata": {
        "id": "8a66c1f7",
        "outputId": "cf1a2a2e-22d2-4d33-fb60-35e702102bde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l==1.0.3\n",
            "  Downloading d2l-1.0.3-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m516.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jupyter==1.0.0 (from d2l==1.0.3)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (1.23.5)\n",
            "Collecting matplotlib==3.7.2 (from d2l==1.0.3)\n",
            "  Downloading matplotlib-3.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (0.1.6)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from d2l==1.0.3) (2.31.0)\n",
            "Collecting pandas==2.0.3 (from d2l==1.0.3)\n",
            "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.10.1 (from d2l==1.0.3)\n",
            "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.5)\n",
            "Collecting qtconsole (from jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading qtconsole-5.5.1-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (6.5.4)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (5.5.6)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter==1.0.0->d2l==1.0.3) (7.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (9.4.0)\n",
            "Collecting pyparsing<3.1,>=2.3.1 (from matplotlib==3.7.2->d2l==1.0.3)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.7.2->d2l==1.0.3) (2.8.2)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.10/dist-packages (from matplotlib-inline==0.1.6->d2l==1.0.3) (5.7.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.3->d2l==1.0.3) (2023.3.post1)\n",
            "Collecting tzdata>=2022.1 (from pandas==2.0.3->d2l==1.0.3)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->d2l==1.0.3) (2023.11.17)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->jupyter==1.0.0->d2l==1.0.3) (6.3.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.6.6)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter==1.0.0->d2l==1.0.3) (3.0.9)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from jupyter-console->jupyter==1.0.0->d2l==1.0.3) (2.16.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.9.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.11.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.4)\n",
            "Requirement already satisfied: jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (3.1.2)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.5.0)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.1.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.9.0)\n",
            "Requirement already satisfied: nbformat>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (5.9.2)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter==1.0.0->d2l==1.0.3) (1.2.1)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.2.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.5.8)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.8.2)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.18.0)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (0.19.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter==1.0.0->d2l==1.0.3) (1.0.0)\n",
            "Collecting qtpy>=2.4.0 (from qtconsole->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading QtPy-2.4.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (4.9.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.1.0)\n",
            "Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.24.0)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (0.2.3)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.19.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (4.19.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter==1.0.0->d2l==1.0.3) (0.2.12)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook->jupyter==1.0.0->d2l==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (21.2.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2.5)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.5.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->jupyter==1.0.0->d2l==1.0.3) (0.8.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter==1.0.0->d2l==1.0.3) (0.13.2)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.7.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (1.16.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter==1.0.0->d2l==1.0.3) (1.2.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter==1.0.0->d2l==1.0.3) (2.21)\n",
            "Installing collected packages: tzdata, scipy, qtpy, pyparsing, jedi, pandas, matplotlib, qtconsole, jupyter, d2l\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed d2l-1.0.3 jedi-0.19.1 jupyter-1.0.0 matplotlib-3.7.2 pandas-2.0.3 pyparsing-3.0.9 qtconsole-5.5.1 qtpy-2.4.1 scipy-1.10.1 tzdata-2023.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install d2l==1.0.3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad19fa4",
      "metadata": {
        "origin_pos": 1,
        "id": "0ad19fa4"
      },
      "source": [
        "# Probability and Statistics\n",
        ":label:`sec_prob`\n",
        "\n",
        "One way or another,\n",
        "machine learning is all about uncertainty.\n",
        "In supervised learning, we want to predict\n",
        "something unknown (the *target*)\n",
        "given something known (the *features*).\n",
        "Depending on our objective,\n",
        "we might attempt to predict\n",
        "the most likely value of the target.\n",
        "Or we might predict the value with the smallest\n",
        "expected distance from the target.\n",
        "And sometimes we wish not only\n",
        "to predict a specific value\n",
        "but to *quantify our uncertainty*.\n",
        "For example, given some features\n",
        "describing a patient,\n",
        "we might want to know *how likely* they are\n",
        "to suffer a heart attack in the next year.\n",
        "In unsupervised learning,\n",
        "we often care about uncertainty.\n",
        "To determine whether a set of measurements are anomalous,\n",
        "it helps to know how likely one is\n",
        "to observe values in a population of interest.\n",
        "Furthermore, in reinforcement learning,\n",
        "we wish to develop agents\n",
        "that act intelligently in various environments.\n",
        "This requires reasoning about\n",
        "how an environment might be expected to change\n",
        "and what rewards one might expect to encounter\n",
        "in response to each of the available actions.\n",
        "\n",
        "*Probability* is the mathematical field\n",
        "concerned with reasoning under uncertainty.\n",
        "Given a probabilistic model of some process,\n",
        "we can reason about the likelihood of various events.\n",
        "The use of probabilities to describe\n",
        "the frequencies of repeatable events\n",
        "(like coin tosses)\n",
        "is fairly uncontroversial.\n",
        "In fact, *frequentist* scholars adhere\n",
        "to an interpretation of probability\n",
        "that applies *only* to such repeatable events.\n",
        "By contrast *Bayesian* scholars\n",
        "use the language of probability more broadly\n",
        "to formalize reasoning under uncertainty.\n",
        "Bayesian probability is characterized\n",
        "by two unique features:\n",
        "(i) assigning degrees of belief\n",
        "to non-repeatable events,\n",
        "e.g., what is the *probability*\n",
        "that a dam will collapse?;\n",
        "and (ii) subjectivity. While Bayesian\n",
        "probability provides unambiguous rules\n",
        "for how one should update their beliefs\n",
        "in light of new evidence,\n",
        "it allows for different individuals\n",
        "to start off with different *prior* beliefs.\n",
        "*Statistics* helps us to reason backwards,\n",
        "starting off with collection and organization of data\n",
        "and backing out to what inferences\n",
        "we might draw about the process\n",
        "that generated the data.\n",
        "Whenever we analyze a dataset, hunting for patterns\n",
        "that we hope might characterize a broader population,\n",
        "we are employing statistical thinking.\n",
        "Many courses, majors, theses, careers, departments,\n",
        "companies, and institutions have been devoted\n",
        "to the study of probability and statistics.\n",
        "While this section only scratches the surface,\n",
        "we will provide the foundation\n",
        "that you need to begin building models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15d26295",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:41.010215Z",
          "iopub.status.busy": "2023-08-18T19:35:41.009884Z",
          "iopub.status.idle": "2023-08-18T19:35:44.240517Z",
          "shell.execute_reply": "2023-08-18T19:35:44.239244Z"
        },
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "15d26295"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import random\n",
        "import torch\n",
        "from torch.distributions.multinomial import Multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "390fa88a",
      "metadata": {
        "origin_pos": 6,
        "id": "390fa88a"
      },
      "source": [
        "## A Simple Example: Tossing Coins\n",
        "\n",
        "Imagine that we plan to toss a coin\n",
        "and want to quantify how likely\n",
        "we are to see heads (vs. tails).\n",
        "If the coin is *fair*,\n",
        "then both outcomes\n",
        "(heads and tails),\n",
        "are equally likely.\n",
        "Moreover if we plan to toss the coin $n$ times\n",
        "then the fraction of heads\n",
        "that we *expect* to see\n",
        "should exactly match\n",
        "the *expected* fraction of tails.\n",
        "One intuitive way to see this\n",
        "is by symmetry:\n",
        "for every possible outcome\n",
        "with $n_\\textrm{h}$ heads and $n_\\textrm{t} = (n - n_\\textrm{h})$ tails,\n",
        "there is an equally likely outcome\n",
        "with $n_\\textrm{t}$ heads and $n_\\textrm{h}$ tails.\n",
        "Note that this is only possible\n",
        "if on average we expect to see\n",
        "$1/2$ of tosses come up heads\n",
        "and $1/2$ come up tails.\n",
        "Of course, if you conduct this experiment\n",
        "many times with $n=1000000$ tosses each,\n",
        "you might never see a trial\n",
        "where $n_\\textrm{h} = n_\\textrm{t}$ exactly.\n",
        "\n",
        "\n",
        "Formally, the quantity $1/2$ is called a *probability*\n",
        "and here it captures the certainty with which\n",
        "any given toss will come up heads.\n",
        "Probabilities assign scores between $0$ and $1$\n",
        "to outcomes of interest, called *events*.\n",
        "Here the event of interest is $\\textrm{heads}$\n",
        "and we denote the corresponding probability $P(\\textrm{heads})$.\n",
        "A probability of $1$ indicates absolute certainty\n",
        "(imagine a trick coin where both sides were heads)\n",
        "and a probability of $0$ indicates impossibility\n",
        "(e.g., if both sides were tails).\n",
        "The frequencies $n_\\textrm{h}/n$ and $n_\\textrm{t}/n$ are not probabilities\n",
        "but rather *statistics*.\n",
        "Probabilities are *theoretical* quantities\n",
        "that underly the data generating process.\n",
        "Here, the probability $1/2$\n",
        "is a property of the coin itself.\n",
        "By contrast, statistics are *empirical* quantities\n",
        "that are computed as functions of the observed data.\n",
        "Our interests in probabilistic and statistical quantities\n",
        "are inextricably intertwined.\n",
        "We often design special statistics called *estimators*\n",
        "that, given a dataset, produce *estimates*\n",
        "of model parameters such as probabilities.\n",
        "Moreover, when those estimators satisfy\n",
        "a nice property called *consistency*,\n",
        "our estimates will converge\n",
        "to the corresponding probability.\n",
        "In turn, these inferred probabilities\n",
        "tell about the likely statistical properties\n",
        "of data from the same population\n",
        "that we might encounter in the future.\n",
        "\n",
        "Suppose that we stumbled upon a real coin\n",
        "for which we did not know\n",
        "the true $P(\\textrm{heads})$.\n",
        "To investigate this quantity\n",
        "with statistical methods,\n",
        "we need to (i) collect some data;\n",
        "and (ii) design an estimator.\n",
        "Data acquisition here is easy;\n",
        "we can toss the coin many times\n",
        "and record all the outcomes.\n",
        "Formally, drawing realizations\n",
        "from some underlying random process\n",
        "is called *sampling*.\n",
        "As you might have guessed,\n",
        "one natural estimator\n",
        "is the ratio of\n",
        "the number of observed *heads*\n",
        "to the total number of tosses.\n",
        "\n",
        "Now, suppose that the coin was in fact fair,\n",
        "i.e., $P(\\textrm{heads}) = 0.5$.\n",
        "To simulate tosses of a fair coin,\n",
        "we can invoke any random number generator.\n",
        "There are some easy ways to draw samples\n",
        "of an event with probability $0.5$.\n",
        "For example Python's `random.random`\n",
        "yields numbers in the interval $[0,1]$\n",
        "where the probability of lying\n",
        "in any sub-interval $[a, b] \\subset [0,1]$\n",
        "is equal to $b-a$.\n",
        "Thus we can get out `0` and `1` with probability `0.5` each\n",
        "by testing whether the returned float number is greater than `0.5`:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3a500e66",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.245216Z",
          "iopub.status.busy": "2023-08-18T19:35:44.244448Z",
          "iopub.status.idle": "2023-08-18T19:35:44.250559Z",
          "shell.execute_reply": "2023-08-18T19:35:44.249469Z"
        },
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "3a500e66",
        "outputId": "7912a444-d97c-4d87-823d-97d41fc44591",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heads, tails:  [48, 52]\n"
          ]
        }
      ],
      "source": [
        "num_tosses = 100\n",
        "heads = sum([random.random() > 0.5 for _ in range(num_tosses)])\n",
        "tails = num_tosses - heads\n",
        "print(\"heads, tails: \", [heads, tails])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "096c1837",
      "metadata": {
        "origin_pos": 8,
        "id": "096c1837"
      },
      "source": [
        "More generally, we can simulate multiple draws\n",
        "from any variable with a finite number\n",
        "of possible outcomes\n",
        "(like the toss of a coin or roll of a die)\n",
        "by calling the multinomial function,\n",
        "setting the first argument\n",
        "to the number of draws\n",
        "and the second as a list of probabilities\n",
        "associated with each of the possible outcomes.\n",
        "To simulate ten tosses of a fair coin,\n",
        "we assign probability vector `[0.5, 0.5]`,\n",
        "interpreting index 0 as heads\n",
        "and index 1 as tails.\n",
        "The function returns a vector\n",
        "with length equal to the number\n",
        "of possible outcomes (here, 2),\n",
        "where the first component tells us\n",
        "the number of occurrences of heads\n",
        "and the second component tells us\n",
        "the number of occurrences of tails.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b70ba754",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.256289Z",
          "iopub.status.busy": "2023-08-18T19:35:44.255841Z",
          "iopub.status.idle": "2023-08-18T19:35:44.292323Z",
          "shell.execute_reply": "2023-08-18T19:35:44.291255Z"
        },
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "b70ba754",
        "outputId": "6bbf7f02-f4bc-4556-c375-5a5e1549e46b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([49., 51.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "fair_probs = torch.tensor([0.5, 0.5])\n",
        "Multinomial(100, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca81b0bc",
      "metadata": {
        "origin_pos": 13,
        "id": "ca81b0bc"
      },
      "source": [
        "Each time you run this sampling process,\n",
        "you will receive a new random value\n",
        "that may differ from the previous outcome.\n",
        "Dividing by the number of tosses\n",
        "gives us the *frequency*\n",
        "of each outcome in our data.\n",
        "Note that these frequencies,\n",
        "just like the probabilities\n",
        "that they are intended\n",
        "to estimate, sum to $1$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d4157453",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.297194Z",
          "iopub.status.busy": "2023-08-18T19:35:44.296806Z",
          "iopub.status.idle": "2023-08-18T19:35:44.309679Z",
          "shell.execute_reply": "2023-08-18T19:35:44.308709Z"
        },
        "origin_pos": 15,
        "tab": [
          "pytorch"
        ],
        "id": "d4157453",
        "outputId": "f388e21f-ee7c-45c3-8720-81d1e09242cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4300, 0.5700])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "Multinomial(100, fair_probs).sample() / 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5135ef92",
      "metadata": {
        "origin_pos": 18,
        "id": "5135ef92"
      },
      "source": [
        "Here, even though our simulated coin is fair\n",
        "(we ourselves set the probabilities `[0.5, 0.5]`),\n",
        "the counts of heads and tails may not be identical.\n",
        "That is because we only drew a relatively small number of samples.\n",
        "If we did not implement the simulation ourselves,\n",
        "and only saw the outcome,\n",
        "how would we know if the coin were slightly unfair\n",
        "or if the possible deviation from $1/2$ was\n",
        "just an artifact of the small sample size?\n",
        "Let's see what happens when we simulate 10,000 tosses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3b639145",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.313908Z",
          "iopub.status.busy": "2023-08-18T19:35:44.313549Z",
          "iopub.status.idle": "2023-08-18T19:35:44.325094Z",
          "shell.execute_reply": "2023-08-18T19:35:44.324133Z"
        },
        "origin_pos": 20,
        "tab": [
          "pytorch"
        ],
        "id": "3b639145",
        "outputId": "0317daab-c2e5-463d-dfd6-7ba628820721",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4970, 0.5030])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "counts = Multinomial(10000, fair_probs).sample()\n",
        "counts / 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8725b688",
      "metadata": {
        "origin_pos": 23,
        "id": "8725b688"
      },
      "source": [
        "In general, for averages of repeated events (like coin tosses),\n",
        "as the number of repetitions grows,\n",
        "our estimates are guaranteed to converge\n",
        "to the true underlying probabilities.\n",
        "The mathematical formulation of this phenomenon\n",
        "is called the *law of large numbers*\n",
        "and the *central limit theorem*\n",
        "tells us that in many situations,\n",
        "as the sample size $n$ grows,\n",
        "these errors should go down\n",
        "at a rate of $(1/\\sqrt{n})$.\n",
        "Let's get some more intuition by studying\n",
        "how our estimate evolves as we grow\n",
        "the number of tosses from 1 to 10,000.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fda7f94d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T19:35:44.329246Z",
          "iopub.status.busy": "2023-08-18T19:35:44.328647Z",
          "iopub.status.idle": "2023-08-18T19:35:44.675913Z",
          "shell.execute_reply": "2023-08-18T19:35:44.674711Z"
        },
        "origin_pos": 24,
        "tab": [
          "pytorch"
        ],
        "id": "fda7f94d",
        "outputId": "fdd44986-24dc-4bb0-ebe3-8adf9544c79a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 1.0000e+00],\n",
            "        [1.0000e+00, 2.0000e+00],\n",
            "        ...,\n",
            "        [4.9950e+03, 5.0030e+03],\n",
            "        [4.9960e+03, 5.0030e+03],\n",
            "        [4.9960e+03, 5.0040e+03]])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 450x350 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"306.596693pt\" height=\"238.79625pt\" viewBox=\"0 0 306.596693 238.79625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-12-20T06:48:16.717857</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 238.79625 \nL 306.596693 238.79625 \nL 306.596693 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \nL 294.88125 7.2 \nL 43.78125 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m2a2145ae2a\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"55.194886\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(52.013636 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"100.853998\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2000 -->\n      <g transform=\"translate(88.128998 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"146.513109\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 4000 -->\n      <g transform=\"translate(133.788109 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"192.17222\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 6000 -->\n      <g transform=\"translate(179.44722 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"237.831332\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 8000 -->\n      <g transform=\"translate(225.106332 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m2a2145ae2a\" x=\"283.490443\" y=\"201.24\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 10000 -->\n      <g transform=\"translate(267.584193 215.838437) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"254.492188\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Samples -->\n     <g transform=\"translate(147.978125 229.516562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-53\" d=\"M 3425 4513 \nL 3425 3897 \nQ 3066 4069 2747 4153 \nQ 2428 4238 2131 4238 \nQ 1616 4238 1336 4038 \nQ 1056 3838 1056 3469 \nQ 1056 3159 1242 3001 \nQ 1428 2844 1947 2747 \nL 2328 2669 \nQ 3034 2534 3370 2195 \nQ 3706 1856 3706 1288 \nQ 3706 609 3251 259 \nQ 2797 -91 1919 -91 \nQ 1588 -91 1214 -16 \nQ 841 59 441 206 \nL 441 856 \nQ 825 641 1194 531 \nQ 1563 422 1919 422 \nQ 2459 422 2753 634 \nQ 3047 847 3047 1241 \nQ 3047 1584 2836 1778 \nQ 2625 1972 2144 2069 \nL 1759 2144 \nQ 1053 2284 737 2584 \nQ 422 2884 422 3419 \nQ 422 4038 858 4394 \nQ 1294 4750 2059 4750 \nQ 2388 4750 2728 4690 \nQ 3069 4631 3425 4513 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-53\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"124.755859\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"222.167969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"285.644531\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"313.427734\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"374.951172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"md89055c162\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"192.42\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 196.219219) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"157.14\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 160.939219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"121.86\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 125.659219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"86.58\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 90.379219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"51.3\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 55.099219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#md89055c162\" x=\"43.78125\" y=\"16.02\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 19.819219) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_14\">\n     <!-- Estimated probability -->\n     <g transform=\"translate(14.798438 157.743437) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"115.283203\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"154.492188\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"182.275391\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"279.6875\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"340.966797\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"380.175781\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"441.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"505.175781\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"536.962891\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"600.439453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"639.302734\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"700.484375\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"763.960938\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"825.240234\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"888.716797\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"916.5\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"944.283203\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"972.066406\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"1011.275391\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path d=\"M 55.194886 16.02 \nL 55.286205 157.139999 \nL 55.331864 142.019998 \nL 55.354693 148.32 \nL 55.377523 133.619998 \nL 55.423182 112.238179 \nL 55.491671 129.419998 \nL 55.5145 133.619998 \nL 55.53733 126.27 \nL 55.674307 104.22 \nL 55.697137 108.054782 \nL 55.742796 114.804 \nL 55.811284 110.520002 \nL 55.948262 93.84353 \nL 55.993921 94.419995 \nL 56.245046 113.602978 \nL 56.56466 94.09869 \nL 56.838614 105.42822 \nL 57.04408 99.917565 \nL 57.06691 101.032045 \nL 57.112569 99.03176 \nL 57.135399 100.117672 \nL 57.226717 98.339995 \nL 57.181058 100.210913 \nL 57.272376 98.467827 \nL 57.386524 101.49217 \nL 57.409353 100.620002 \nL 57.500671 99.03176 \nL 57.455012 100.692003 \nL 57.523501 99.938446 \nL 57.546331 100.82769 \nL 57.59199 99.227546 \nL 57.614819 100.098505 \nL 57.843115 95.927688 \nL 58.002922 98.529672 \nL 58.025751 97.869598 \nL 58.07141 99.358585 \nL 58.117069 100.801394 \nL 58.185558 100.210913 \nL 58.231217 98.954333 \nL 58.299706 99.713431 \nL 58.368195 99.18 \nL 58.413854 100.493242 \nL 58.642149 94.935793 \nL 58.710638 95.684514 \nL 58.733467 95.173847 \nL 58.779127 96.404814 \nL 58.824786 95.399998 \nL 58.916104 97.766337 \nL 58.961763 96.781445 \nL 59.030252 95.347816 \nL 59.075911 96.483156 \nL 59.12157 97.592253 \nL 59.167229 96.659995 \nL 59.395525 94.208112 \nL 59.418354 94.736128 \nL 59.464013 93.898719 \nL 59.486843 93.486666 \nL 59.532502 94.522614 \nL 59.737968 97.163996 \nL 59.760798 96.760301 \nL 59.806457 97.702757 \nL 59.829286 97.302353 \nL 59.874945 98.225821 \nL 59.943434 97.889859 \nL 60.011923 98.395468 \nL 60.103241 96.869996 \nL 60.331536 100.317349 \nL 60.354366 99.945996 \nL 60.377196 99.577891 \nL 60.422855 100.385218 \nL 60.468514 99.657926 \nL 60.605491 101.255294 \nL 60.628321 100.898661 \nL 60.65115 100.545004 \nL 60.719639 100.953335 \nL 60.993594 103.874112 \nL 61.19906 102.215456 \nL 61.221889 102.555845 \nL 61.267548 101.907641 \nL 61.290378 101.587166 \nL 61.336037 102.259995 \nL 61.381696 101.62588 \nL 61.518673 102.316404 \nL 61.632821 100.791731 \nL 61.67848 101.434741 \nL 61.906776 103.32305 \nL 61.952435 102.735155 \nL 61.998094 103.335046 \nL 62.272049 105.638006 \nL 62.294878 105.350772 \nL 62.340537 105.905352 \nL 62.363367 106.18 \nL 62.409026 105.611168 \nL 62.454685 106.155423 \nL 62.568833 104.764444 \nL 62.614492 105.302206 \nL 62.637322 105.568622 \nL 62.682981 105.024257 \nL 62.774299 104.484865 \nL 62.797128 104.748142 \nL 62.865617 105.528605 \nL 62.934106 105.257647 \nL 62.956935 104.995952 \nL 63.002594 105.505715 \nL 63.139572 106.999944 \nL 63.20806 106.725679 \nL 63.367867 105.939775 \nL 63.390697 106.18 \nL 63.436356 105.681876 \nL 63.710311 103.276682 \nL 63.73314 103.514399 \nL 63.892947 104.681781 \nL 63.915777 104.450289 \nL 63.961436 103.990905 \nL 64.029924 104.22 \nL 64.144072 104.444427 \nL 64.166902 104.22 \nL 64.212561 104.665452 \nL 64.349538 105.097609 \nL 64.486516 104.652352 \nL 64.555004 104.863793 \nL 64.577834 104.648156 \nL 64.600663 104.43356 \nL 64.646322 104.85759 \nL 64.714811 105.064022 \nL 64.737641 104.851502 \nL 64.828959 104.428508 \nL 64.851788 104.636039 \nL 64.943107 105.456451 \nL 65.034425 105.445001 \nL 65.148573 105.229153 \nL 65.217061 105.823635 \nL 65.28555 105.613681 \nL 65.376868 105.206579 \nL 65.399698 105.401251 \nL 65.445357 105.788002 \nL 65.513846 105.582916 \nL 65.742141 104.410497 \nL 65.879118 105.160301 \nL 65.901948 104.970639 \nL 66.038925 103.849414 \nL 66.084584 104.22 \nL 66.153073 104.403369 \nL 66.175903 104.22 \nL 66.198732 104.037388 \nL 66.244391 104.401855 \nL 66.267221 104.22 \nL 66.427028 104.756716 \nL 66.609664 104.043949 \nL 66.678153 103.870001 \nL 66.723812 104.22 \nL 66.952108 103.194418 \nL 67.089085 103.544133 \nL 67.157574 103.379995 \nL 67.180403 103.549274 \nL 67.203233 103.717913 \nL 67.248892 103.386356 \nL 67.271721 103.554342 \nL 67.34021 103.061655 \nL 67.408699 103.23269 \nL 67.477187 103.401822 \nL 67.500017 103.239997 \nL 67.568506 103.407847 \nL 67.659824 102.768811 \nL 67.728312 102.937092 \nL 67.751142 102.779347 \nL 67.773972 102.622169 \nL 67.819631 102.946355 \nL 67.910949 103.271614 \nL 67.933778 103.11553 \nL 67.956608 102.960003 \nL 68.002267 103.278364 \nL 68.253392 104.373929 \nL 68.321881 104.526249 \nL 68.413199 103.915865 \nL 68.550176 104.22 \nL 68.664324 103.772282 \nL 68.687154 103.922026 \nL 68.755642 104.071759 \nL 68.778472 103.924024 \nL 68.915449 103.340934 \nL 68.938279 103.48866 \nL 69.006768 103.346728 \nL 69.052427 103.639739 \nL 69.120915 103.209527 \nL 69.189404 103.358115 \nL 69.212234 103.502928 \nL 69.257893 103.219347 \nL 69.280722 103.078257 \nL 69.326381 103.366452 \nL 69.349211 103.225793 \nL 69.39487 103.512138 \nL 69.463359 103.374633 \nL 69.486188 103.235308 \nL 69.531847 103.518888 \nL 69.760143 104.358026 \nL 69.89712 103.809765 \nL 69.91995 103.946934 \nL 69.942779 104.083683 \nL 69.988438 103.812299 \nL 70.171075 103.011785 \nL 70.193904 103.147661 \nL 70.216734 103.283127 \nL 70.262393 103.019093 \nL 70.285223 102.887675 \nL 70.330882 103.157345 \nL 70.353711 103.026316 \nL 70.673325 104.349898 \nL 70.696155 104.22 \nL 70.741814 104.478651 \nL 70.764643 104.349136 \nL 71.061428 105.487242 \nL 71.084257 105.358884 \nL 71.129916 105.607982 \nL 71.175575 105.855661 \nL 71.244064 105.723408 \nL 71.312553 105.34277 \nL 71.358212 105.588405 \nL 71.563678 106.185462 \nL 71.791973 105.431537 \nL 72.043098 106.248958 \nL 72.157246 105.879676 \nL 72.180076 105.995837 \nL 72.385542 106.559523 \nL 72.49969 106.427905 \nL 72.591008 106.878714 \nL 72.636667 106.641176 \nL 72.796474 106.276479 \nL 72.819303 106.387919 \nL 72.864962 106.154708 \nL 72.887792 106.265875 \nL 73.138917 105.452781 \nL 73.161747 105.563149 \nL 73.207406 105.336457 \nL 73.230235 105.223539 \nL 73.275894 105.443455 \nL 73.412872 105.655044 \nL 73.48136 105.75965 \nL 73.549849 105.425218 \nL 73.618338 105.311585 \nL 73.663997 105.526665 \nL 73.823804 105.191602 \nL 74.00644 105.609817 \nL 74.097758 105.390326 \nL 74.120588 105.49518 \nL 74.189077 105.384707 \nL 74.234736 105.593173 \nL 74.348884 105.270001 \nL 74.371713 105.373625 \nL 74.394543 105.477006 \nL 74.440202 105.265023 \nL 74.691327 104.529471 \nL 74.714156 104.632148 \nL 74.759816 104.425596 \nL 74.828304 104.527316 \nL 74.873963 104.322204 \nL 74.988111 104.62645 \nL 75.010941 104.524488 \nL 75.102259 104.321032 \nL 75.125088 104.421832 \nL 75.284895 104.920796 \nL 75.307725 104.820001 \nL 75.444702 104.617297 \nL 75.695827 105.299199 \nL 75.809975 105.000531 \nL 75.832805 105.097126 \nL 76.015441 105.47586 \nL 76.0611 105.280326 \nL 76.106759 105.470382 \nL 76.198078 105.656484 \nL 76.220907 105.559264 \nL 76.540521 104.596926 \nL 76.58618 104.784179 \nL 76.631839 104.595317 \nL 76.654669 104.501188 \nL 76.700328 104.687658 \nL 76.745987 104.873335 \nL 76.814476 104.778228 \nL 76.860135 104.591369 \nL 76.928623 104.682748 \nL 76.997112 104.773555 \nL 77.019942 104.680814 \nL 77.11126 104.495337 \nL 77.134089 104.586737 \nL 77.293896 105.039197 \nL 77.316726 104.947424 \nL 77.339555 104.855839 \nL 77.385214 105.035828 \nL 77.408044 104.944438 \nL 77.61351 105.386431 \nL 77.750487 105.022627 \nL 77.773317 105.11091 \nL 77.796146 105.199009 \nL 77.841806 105.019394 \nL 77.910294 104.751328 \nL 77.978783 104.838018 \nL 78.13859 105.272088 \nL 78.161419 105.183458 \nL 78.252738 105.005163 \nL 78.275567 105.091543 \nL 78.389715 105.347434 \nL 78.412544 105.259687 \nL 78.503863 105.083016 \nL 78.526692 105.168386 \nL 78.686499 105.418836 \nL 78.846306 105.155585 \nL 78.891965 105.323561 \nL 78.937624 105.151989 \nL 78.983283 104.981075 \nL 79.028942 105.14842 \nL 79.188749 105.393765 \nL 79.257238 105.47403 \nL 79.325727 105.220379 \nL 79.417045 105.548813 \nL 79.462704 105.380527 \nL 79.485534 105.296618 \nL 79.531193 105.459926 \nL 79.554022 105.376179 \nL 79.713829 105.61479 \nL 79.850807 105.117502 \nL 79.896466 105.278728 \nL 79.919295 105.359115 \nL 79.964954 105.194588 \nL 80.010613 105.03066 \nL 80.056273 105.191008 \nL 80.079102 105.270963 \nL 80.124761 105.107651 \nL 80.147591 105.026218 \nL 80.19325 105.185693 \nL 80.216079 105.104412 \nL 80.398716 105.417285 \nL 80.467205 105.175236 \nL 80.512864 105.332435 \nL 80.741159 105.794999 \nL 80.923796 105.314682 \nL 80.946625 105.391835 \nL 80.969455 105.468852 \nL 81.015114 105.310812 \nL 81.037943 105.387698 \nL 81.060773 105.308888 \nL 81.106432 105.462254 \nL 81.357557 105.988614 \nL 81.403216 105.832009 \nL 81.448875 105.982468 \nL 81.585853 106.430718 \nL 81.631512 106.274702 \nL 81.768489 106.112703 \nL 81.814148 106.260618 \nL 81.882637 106.18 \nL 81.951126 105.949412 \nL 82.019614 106.019999 \nL 82.065273 106.166689 \nL 82.110933 106.013901 \nL 82.22508 105.9319 \nL 82.362058 106.219497 \nL 82.384887 106.143826 \nL 82.453376 106.212804 \nL 82.544694 105.911907 \nL 82.681671 106.049875 \nL 82.818649 105.895142 \nL 82.864308 106.037805 \nL 82.909967 105.889628 \nL 83.024115 105.521313 \nL 83.069774 105.663534 \nL 83.092603 105.734474 \nL 83.138263 105.588 \nL 83.320899 105.149928 \nL 83.343729 105.220647 \nL 83.526365 105.498261 \nL 83.572024 105.354404 \nL 83.617683 105.494155 \nL 83.731831 105.700576 \nL 83.754661 105.628948 \nL 83.891638 105.482006 \nL 83.937297 105.62 \nL 84.005786 105.546842 \nL 84.119933 105.193815 \nL 84.165593 105.331184 \nL 84.256911 105.604618 \nL 84.30257 105.4642 \nL 84.416718 105.252789 \nL 84.439547 105.32078 \nL 84.576525 105.589566 \nL 84.599354 105.520078 \nL 84.690672 105.379628 \nL 84.713502 105.446893 \nL 84.850479 105.576923 \nL 85.033116 105.2989 \nL 85.170093 105.42822 \nL 85.238582 105.224553 \nL 85.284241 105.35677 \nL 85.444048 105.550317 \nL 85.466877 105.482847 \nL 85.512536 105.613681 \nL 85.535366 105.546316 \nL 85.695173 106.001152 \nL 85.740832 105.866754 \nL 85.946298 105.528605 \nL 86.106105 105.71712 \nL 86.174593 105.778765 \nL 86.220253 105.646764 \nL 86.288741 105.837755 \nL 86.3344 105.706154 \nL 86.35723 105.640497 \nL 86.402889 105.767368 \nL 86.585525 106.014768 \nL 86.676844 105.753915 \nL 86.722503 105.879334 \nL 86.768162 106.004391 \nL 86.813821 105.874545 \nL 86.905139 105.74288 \nL 86.927969 105.805193 \nL 87.042117 105.989056 \nL 87.064946 105.924651 \nL 87.201923 105.6659 \nL 87.224753 105.727692 \nL 87.293242 105.912538 \nL 87.338901 105.784937 \nL 87.521537 105.402639 \nL 87.544367 105.464005 \nL 87.681344 105.582643 \nL 87.863981 105.32866 \nL 87.88681 105.389433 \nL 87.932469 105.264876 \nL 88.320572 104.341487 \nL 88.343401 104.402107 \nL 88.366231 104.462643 \nL 88.41189 104.341156 \nL 88.434719 104.401608 \nL 88.548867 104.22 \nL 88.571697 104.280289 \nL 88.754333 104.519798 \nL 88.822822 104.579025 \nL 89.073947 103.923035 \nL 89.096777 103.982588 \nL 89.142436 103.864355 \nL 89.165265 103.80536 \nL 89.210924 103.924223 \nL 89.279413 103.865785 \nL 89.325072 103.984176 \nL 89.347902 103.925411 \nL 89.393561 104.043487 \nL 89.41639 103.984796 \nL 89.530538 104.278606 \nL 89.576197 104.161478 \nL 89.644686 103.986363 \nL 89.690345 104.103334 \nL 89.758834 104.045348 \nL 89.850152 104.278065 \nL 89.94147 104.162087 \nL 89.9643 104.22 \nL 90.215425 104.852054 \nL 90.283913 104.793474 \nL 90.352402 104.73512 \nL 90.375232 104.791986 \nL 90.512209 104.903721 \nL 90.672016 104.617039 \nL 90.694845 104.673469 \nL 90.786164 104.785383 \nL 90.808993 104.728522 \nL 90.877482 104.671151 \nL 90.900311 104.727218 \nL 90.945971 104.839143 \nL 90.99163 104.725925 \nL 91.037289 104.612997 \nL 91.082948 104.724642 \nL 91.151437 104.891572 \nL 91.197096 104.778933 \nL 91.219925 104.722724 \nL 91.265584 104.833665 \nL 91.288414 104.777524 \nL 91.379732 104.88734 \nL 91.402562 104.831341 \nL 91.49388 104.718933 \nL 91.516709 104.774023 \nL 91.585198 104.93887 \nL 91.630857 104.827514 \nL 91.699346 104.881499 \nL 91.745005 104.770563 \nL 91.790664 104.879849 \nL 91.836323 104.769191 \nL 91.950471 104.603239 \nL 91.973301 104.657719 \nL 91.99613 104.712125 \nL 92.041789 104.602293 \nL 92.064619 104.547477 \nL 92.110278 104.656095 \nL 92.201596 104.763771 \nL 92.224426 104.709092 \nL 92.338573 104.653414 \nL 92.475551 104.759781 \nL 92.566869 104.650769 \nL 92.589699 104.704318 \nL 92.612528 104.757804 \nL 92.658187 104.649718 \nL 92.795165 104.541116 \nL 92.840824 104.647636 \nL 92.886483 104.540338 \nL 93.02346 104.432788 \nL 93.114778 104.538414 \nL 93.137608 104.485185 \nL 93.160437 104.43202 \nL 93.206097 104.537646 \nL 93.228926 104.484549 \nL 93.343074 104.642011 \nL 93.365903 104.58904 \nL 93.411563 104.483282 \nL 93.480051 104.535375 \nL 93.571369 104.639503 \nL 93.594199 104.586843 \nL 93.639858 104.481721 \nL 93.685517 104.585975 \nL 93.868154 104.792391 \nL 94.005131 104.686665 \nL 94.07362 104.634083 \nL 94.187767 104.89092 \nL 94.301915 104.734584 \nL 94.324745 104.785714 \nL 94.347574 104.836782 \nL 94.393233 104.73339 \nL 94.416063 104.7844 \nL 94.484552 104.732197 \nL 94.507381 104.783086 \nL 94.57587 104.833207 \nL 94.598699 104.781782 \nL 94.758506 104.626923 \nL 94.918313 104.777266 \nL 95.283586 104.169805 \nL 95.420563 104.270027 \nL 95.489052 104.319885 \nL 95.534711 104.22 \nL 95.694518 104.369071 \nL 95.808666 104.22 \nL 95.831495 104.269522 \nL 95.877155 104.368404 \nL 95.945643 104.318766 \nL 96.014132 104.367904 \nL 96.10545 104.170804 \nL 96.219598 104.318109 \nL 96.242427 104.269028 \nL 96.356575 104.122217 \nL 96.379405 104.17114 \nL 96.562041 104.365948 \nL 96.721848 104.22 \nL 96.790337 104.268381 \nL 96.813166 104.22 \nL 96.972973 104.075492 \nL 97.041462 104.123816 \nL 97.064291 104.075807 \nL 97.201269 103.980454 \nL 97.315417 104.124446 \nL 97.338246 104.076743 \nL 97.475223 103.98201 \nL 97.589371 104.030123 \nL 97.726349 103.841455 \nL 97.749178 103.888959 \nL 97.954644 104.125866 \nL 98.000303 104.031942 \nL 98.045962 104.126066 \nL 98.091621 104.22 \nL 98.137281 104.126265 \nL 98.365576 103.847059 \nL 98.66236 104.2663 \nL 98.68519 104.22 \nL 98.730849 104.312452 \nL 98.799338 104.358462 \nL 98.822167 104.312257 \nL 98.981974 104.174042 \nL 99.233099 104.494196 \nL 99.278758 104.402606 \nL 99.324417 104.493628 \nL 99.347247 104.539071 \nL 99.392906 104.447671 \nL 99.575543 104.265348 \nL 99.598372 104.310649 \nL 99.644031 104.22 \nL 99.758179 103.994196 \nL 99.826668 104.039628 \nL 100.009304 104.22 \nL 100.123452 104.085617 \nL 100.146282 104.130461 \nL 100.306088 104.353841 \nL 100.328918 104.309182 \nL 100.374577 104.22 \nL 100.443066 104.264481 \nL 100.465895 104.308914 \nL 100.511554 104.22 \nL 100.580043 104.175651 \nL 100.602873 104.22 \nL 100.694191 104.308467 \nL 100.71702 104.264212 \nL 100.922486 103.955924 \nL 100.945316 104.000052 \nL 100.990975 104.088162 \nL 101.059464 104.044475 \nL 101.219271 103.826441 \nL 101.2421 103.870348 \nL 101.401907 104.002218 \nL 101.447566 103.915412 \nL 101.516055 103.959309 \nL 101.561714 104.046378 \nL 101.607373 103.959825 \nL 101.630203 103.916611 \nL 101.675862 104.003501 \nL 101.698691 103.960329 \nL 101.76718 104.090359 \nL 101.835669 104.047398 \nL 101.858498 104.004353 \nL 101.904157 104.090738 \nL 101.926987 104.133867 \nL 101.972646 104.047903 \nL 102.132453 103.834095 \nL 102.155282 103.877141 \nL 102.337919 104.049238 \nL 102.429237 103.964346 \nL 102.452067 104.007055 \nL 102.474896 104.049732 \nL 102.520555 103.96484 \nL 102.726021 103.754229 \nL 102.77168 103.839279 \nL 102.81734 103.755123 \nL 102.840169 103.713108 \nL 102.885828 103.797989 \nL 102.908658 103.756016 \nL 103.091294 103.925864 \nL 103.159783 103.968236 \nL 103.205442 103.884637 \nL 103.410908 104.094775 \nL 103.433738 104.053118 \nL 103.479397 104.136632 \nL 103.707692 104.385947 \nL 103.79901 104.22 \nL 103.84467 104.302737 \nL 103.935988 104.385168 \nL 103.958817 104.343816 \nL 104.141454 104.178879 \nL 104.34692 104.383786 \nL 104.438238 104.301743 \nL 104.461068 104.342554 \nL 104.575215 104.464546 \nL 104.598045 104.423693 \nL 104.735022 104.260627 \nL 104.757852 104.301217 \nL 104.803511 104.382282 \nL 104.84917 104.301065 \nL 104.986147 104.139156 \nL 105.008977 104.179594 \nL 105.123125 104.300623 \nL 105.145954 104.260291 \nL 105.282932 104.179815 \nL 105.305761 104.22 \nL 105.35142 104.139745 \nL 105.37425 104.179888 \nL 105.465568 104.099896 \nL 105.488398 104.139965 \nL 105.648204 104.259891 \nL 105.785182 104.180214 \nL 105.89933 104.299388 \nL 105.922159 104.259676 \nL 106.013477 104.180393 \nL 106.036307 104.22 \nL 106.196114 104.338391 \nL 106.310262 104.22 \nL 106.333091 104.259355 \nL 106.470068 104.337754 \nL 106.607046 104.25915 \nL 106.744023 104.337129 \nL 106.881 104.25894 \nL 107.086466 104.452717 \nL 107.223444 104.297369 \nL 107.246273 104.336004 \nL 107.383251 104.412832 \nL 107.520228 104.335394 \nL 107.565887 104.412159 \nL 107.611546 104.335194 \nL 107.771353 104.143435 \nL 107.794183 104.181739 \nL 107.817012 104.22 \nL 107.862671 104.143572 \nL 107.885501 104.105405 \nL 107.93116 104.181833 \nL 108.136626 104.372068 \nL 108.250774 104.333806 \nL 108.319262 104.371547 \nL 108.342092 104.333612 \nL 108.547558 104.14455 \nL 108.661706 104.257646 \nL 108.684535 104.22 \nL 108.844342 104.107455 \nL 108.93566 104.257452 \nL 108.98132 104.18258 \nL 109.118297 104.108023 \nL 109.163956 104.182706 \nL 109.209615 104.108212 \nL 109.346592 103.959825 \nL 109.369422 103.997087 \nL 109.392252 104.034318 \nL 109.437911 103.960256 \nL 109.711865 103.666214 \nL 109.780354 103.777528 \nL 109.826013 103.704212 \nL 109.917331 103.631506 \nL 109.940161 103.668517 \nL 110.099968 103.85342 \nL 110.122797 103.816925 \nL 110.168456 103.74403 \nL 110.214116 103.817598 \nL 110.328263 103.854934 \nL 110.396752 103.818923 \nL 110.419582 103.855534 \nL 110.5109 103.928913 \nL 110.533729 103.89266 \nL 110.716366 103.74873 \nL 110.899002 103.894804 \nL 111.104468 103.715999 \nL 111.195786 103.788705 \nL 111.218616 103.752957 \nL 111.332764 103.646342 \nL 111.355593 103.682416 \nL 111.675207 104.041815 \nL 111.698037 104.006266 \nL 111.743696 104.077626 \nL 111.835014 104.148924 \nL 111.857844 104.113438 \nL 111.880673 104.077973 \nL 111.926332 104.149039 \nL 112.06331 104.22 \nL 112.200287 104.078762 \nL 112.223116 104.114121 \nL 112.314435 104.184767 \nL 112.337264 104.149554 \nL 112.474242 104.079445 \nL 112.56556 104.149828 \nL 112.588389 104.114794 \nL 112.725367 104.045074 \nL 112.816685 104.045348 \nL 112.930833 104.010829 \nL 112.953662 104.045758 \nL 112.999321 103.976258 \nL 113.09064 103.976637 \nL 113.181958 103.977026 \nL 113.273276 103.977404 \nL 113.455912 104.116361 \nL 113.478742 104.081864 \nL 113.524401 104.150984 \nL 113.707038 104.2888 \nL 113.798356 104.22 \nL 113.821185 104.254334 \nL 114.003822 104.39113 \nL 114.140799 104.32244 \nL 114.186458 104.390599 \nL 114.232117 104.322283 \nL 114.369095 104.254014 \nL 114.460413 104.253961 \nL 114.528902 104.152151 \nL 114.574561 104.22 \nL 114.665879 104.355382 \nL 114.711538 104.287638 \nL 114.780027 104.253782 \nL 114.802856 104.287533 \nL 114.962663 104.388386 \nL 115.12247 104.287176 \nL 115.282277 104.387492 \nL 115.419254 104.320264 \nL 115.579061 104.420002 \nL 115.601891 104.386604 \nL 115.64755 104.45307 \nL 115.853016 104.684562 \nL 115.875845 104.651216 \nL 115.967164 104.650569 \nL 116.1498 104.781362 \nL 116.286777 104.648314 \nL 116.309607 104.681092 \nL 116.469414 104.778433 \nL 116.606391 104.711636 \nL 116.697709 104.776362 \nL 116.720539 104.743442 \nL 116.926005 104.513458 \nL 116.948834 104.545942 \nL 117.062982 104.708014 \nL 117.108641 104.642631 \nL 117.222789 104.609406 \nL 117.245619 104.641701 \nL 117.291278 104.57656 \nL 117.359766 104.479029 \nL 117.405426 104.54355 \nL 117.633721 104.735788 \nL 117.770698 104.605994 \nL 117.793528 104.63801 \nL 117.884846 104.701616 \nL 117.907676 104.669343 \nL 118.044653 104.604312 \nL 118.158801 104.635587 \nL 118.478415 104.315422 \nL 118.501244 104.34718 \nL 118.546903 104.283543 \nL 118.683881 104.22 \nL 118.820858 104.346544 \nL 118.843688 104.31487 \nL 118.889347 104.251601 \nL 118.957835 104.346271 \nL 119.117642 104.440421 \nL 119.300279 104.376994 \nL 119.437256 104.376662 \nL 119.528574 104.376436 \nL 119.551404 104.407659 \nL 119.779699 104.531658 \nL 120.099313 104.282024 \nL 120.28195 104.405556 \nL 120.304779 104.374575 \nL 120.601563 104.15845 \nL 120.738541 104.22 \nL 120.76137 104.189298 \nL 120.7842 104.158618 \nL 120.852689 104.250654 \nL 121.012495 104.281167 \nL 121.28645 104.098182 \nL 121.377768 104.09835 \nL 121.400598 104.067985 \nL 121.697382 103.856785 \nL 121.857189 103.887855 \nL 122.039825 103.828533 \nL 122.222462 103.94972 \nL 122.245291 103.919797 \nL 122.450757 103.83093 \nL 122.473587 103.86098 \nL 122.542076 103.771682 \nL 122.656223 103.7426 \nL 122.679053 103.772587 \nL 122.861689 103.833286 \nL 122.953008 103.774395 \nL 122.998667 103.834074 \nL 123.204133 103.924024 \nL 123.615065 103.572774 \nL 123.706383 103.63239 \nL 123.752042 103.574056 \nL 123.86619 103.604443 \nL 123.957508 103.663806 \nL 124.003167 103.605673 \nL 124.231463 103.374443 \nL 124.277122 103.433281 \nL 124.551077 103.61052 \nL 124.619565 103.582131 \nL 124.665224 103.640496 \nL 124.802202 103.75731 \nL 124.847861 103.699818 \nL 125.098986 103.557707 \nL 125.281622 103.616871 \nL 125.464259 103.446571 \nL 125.509918 103.504326 \nL 125.669725 103.534512 \nL 125.89802 103.42284 \nL 126.263293 103.710174 \nL 126.4231 103.683058 \nL 126.651396 103.797453 \nL 126.902521 103.65857 \nL 127.085157 103.715999 \nL 127.153646 103.688504 \nL 127.199305 103.744755 \nL 127.427601 103.857721 \nL 127.541748 103.830478 \nL 127.564578 103.858415 \nL 127.701555 103.859098 \nL 127.929851 103.749529 \nL 128.043999 103.833159 \nL 128.089658 103.77817 \nL 128.272294 103.72419 \nL 128.295124 103.751874 \nL 128.363612 103.669778 \nL 128.614737 103.534575 \nL 128.774544 103.563427 \nL 128.888692 103.53713 \nL 128.911522 103.564646 \nL 129.00284 103.620004 \nL 129.048499 103.565855 \nL 129.162647 103.539654 \nL 129.185476 103.567064 \nL 129.231135 103.621854 \nL 129.299624 103.540916 \nL 129.413772 103.460587 \nL 129.459431 103.515271 \nL 129.550749 103.516133 \nL 129.573579 103.48928 \nL 129.664897 103.490184 \nL 129.687727 103.517427 \nL 129.847533 103.545899 \nL 130.03017 103.386146 \nL 130.075829 103.44042 \nL 130.098659 103.467537 \nL 130.167147 103.38767 \nL 130.326954 103.362646 \nL 130.509591 103.471637 \nL 130.53242 103.445141 \nL 130.55525 103.418666 \nL 130.623738 103.499458 \nL 130.943352 103.715084 \nL 131.171648 103.504652 \nL 131.217307 103.558033 \nL 131.240136 103.584707 \nL 131.308625 103.505935 \nL 131.445602 103.454425 \nL 131.468432 103.481037 \nL 131.673898 103.561986 \nL 131.696727 103.535869 \nL 131.765216 103.615346 \nL 131.947853 103.721698 \nL 131.970682 103.695622 \nL 132.039171 103.669894 \nL 132.08483 103.722581 \nL 132.267466 103.775993 \nL 132.518591 103.647278 \nL 132.632739 103.67411 \nL 132.655569 103.648287 \nL 132.838205 103.597777 \nL 133.066501 103.703003 \nL 133.180649 103.729573 \nL 133.363285 103.782218 \nL 133.523092 103.70601 \nL 133.545921 103.731854 \nL 133.751387 103.810007 \nL 133.979683 103.657887 \nL 134.002513 103.683594 \nL 134.344956 103.914813 \nL 134.459104 103.889852 \nL 134.481933 103.915339 \nL 134.64174 103.991967 \nL 134.66457 103.966701 \nL 134.801547 103.967132 \nL 135.029843 104.06871 \nL 135.189649 103.993523 \nL 135.212479 104.018747 \nL 135.509263 104.245066 \nL 135.532093 104.22 \nL 135.554922 104.194955 \nL 135.623411 104.270058 \nL 135.714729 104.320001 \nL 135.760388 104.269974 \nL 135.943025 104.22 \nL 136.239809 104.393869 \nL 136.376786 104.393575 \nL 136.490934 104.368566 \nL 136.673571 104.269412 \nL 136.6964 104.294099 \nL 136.71923 104.318766 \nL 136.787718 104.244672 \nL 136.924696 104.146106 \nL 136.970355 104.195386 \nL 137.175821 104.269107 \nL 137.289969 104.195481 \nL 137.335628 104.244509 \nL 137.472605 104.2934 \nL 137.495435 104.268918 \nL 137.655241 104.244414 \nL 137.74656 104.341923 \nL 137.815048 104.268728 \nL 137.997685 104.22 \nL 138.180321 104.268513 \nL 138.385787 104.195807 \nL 138.682571 104.364671 \nL 138.819549 104.31629 \nL 138.842378 104.340325 \nL 138.979356 104.340131 \nL 139.25331 104.196049 \nL 139.321799 104.22 \nL 139.367458 104.172171 \nL 139.390288 104.148272 \nL 139.458776 104.22 \nL 139.572924 104.243857 \nL 139.595754 104.22 \nL 139.687072 104.22 \nL 139.709902 104.24382 \nL 140.006686 104.457354 \nL 140.029515 104.43356 \nL 140.120834 104.433329 \nL 140.143663 104.45697 \nL 140.257811 104.480317 \nL 140.28064 104.456587 \nL 140.417618 104.408968 \nL 140.440447 104.43253 \nL 140.577425 104.432188 \nL 140.714402 104.431852 \nL 140.782891 104.455199 \nL 140.82855 104.408058 \nL 141.011186 104.313829 \nL 141.034016 104.337255 \nL 141.102504 104.360597 \nL 141.148164 104.313682 \nL 141.376459 104.22 \nL 141.399289 104.243352 \nL 141.467777 104.173338 \nL 141.581925 104.1967 \nL 141.83305 104.312941 \nL 141.85588 104.289689 \nL 141.924368 104.359261 \nL 142.107005 104.405293 \nL 142.221153 104.428182 \nL 142.312471 104.427967 \nL 142.3353 104.404809 \nL 142.35813 104.381667 \nL 142.426619 104.450767 \nL 142.586426 104.473383 \nL 142.677744 104.427094 \nL 142.723403 104.472984 \nL 143.043017 104.655385 \nL 143.157164 104.586164 \nL 143.202824 104.631723 \nL 143.453949 104.744593 \nL 143.636585 104.697989 \nL 144.024688 104.945179 \nL 144.230154 104.87568 \nL 144.321472 104.829832 \nL 144.481279 104.806196 \nL 144.686745 104.872336 \nL 144.846552 104.848716 \nL 145.120506 104.981117 \nL 145.234654 105.002508 \nL 145.348802 104.979187 \nL 145.645586 104.820911 \nL 145.851052 104.886162 \nL 146.170666 104.706805 \nL 146.376132 104.771941 \nL 146.49028 104.793301 \nL 146.672916 104.836167 \nL 146.809893 104.835247 \nL 147.015359 104.899642 \nL 147.243655 104.810481 \nL 147.426291 104.852964 \nL 147.677416 104.742406 \nL 147.905712 104.827977 \nL 148.225326 104.652777 \nL 148.407962 104.695124 \nL 148.636258 104.607787 \nL 148.796065 104.628631 \nL 148.910212 104.649613 \nL 149.001531 104.606278 \nL 149.161338 104.584198 \nL 149.298315 104.583667 \nL 149.435292 104.583136 \nL 149.595099 104.603849 \nL 149.823395 104.517827 \nL 149.937542 104.49622 \nL 150.143008 104.43202 \nL 150.234327 104.389453 \nL 150.462622 104.304524 \nL 150.668088 104.367599 \nL 150.827895 104.346303 \nL 150.987702 104.367105 \nL 151.124679 104.366895 \nL 151.398634 104.49203 \nL 151.558441 104.470686 \nL 151.763907 104.532694 \nL 151.992202 104.448769 \nL 152.083521 104.406996 \nL 152.197668 104.42753 \nL 152.288987 104.385868 \nL 152.425964 104.385636 \nL 152.65426 104.467868 \nL 152.814066 104.44684 \nL 152.996703 104.487583 \nL 153.15651 104.466596 \nL 153.384805 104.548034 \nL 153.498953 104.568132 \nL 153.63593 104.567649 \nL 153.772908 104.567165 \nL 153.955544 104.607287 \nL 154.297988 104.42313 \nL 154.457794 104.443086 \nL 154.731749 104.321126 \nL 155.005704 104.441861 \nL 155.233999 104.360865 \nL 155.370977 104.36067 \nL 155.462295 104.400698 \nL 155.69059 104.480412 \nL 155.804738 104.500126 \nL 155.987375 104.539565 \nL 156.170011 104.499112 \nL 156.306988 104.498738 \nL 156.398307 104.538267 \nL 156.512454 104.518042 \nL 156.786409 104.398343 \nL 156.969046 104.437582 \nL 157.311489 104.259428 \nL 157.516955 104.318371 \nL 157.722421 104.259271 \nL 157.836569 104.239614 \nL 158.087694 104.141742 \nL 158.27033 104.18094 \nL 158.475796 104.122543 \nL 158.612774 104.12267 \nL 158.704092 104.161656 \nL 158.841069 104.16173 \nL 159.000876 104.142426 \nL 159.206342 104.200643 \nL 159.32049 104.22 \nL 159.525956 104.277886 \nL 159.640104 104.297096 \nL 159.777081 104.296996 \nL 160.028206 104.200801 \nL 160.210843 104.239167 \nL 160.302161 104.27746 \nL 160.598945 104.410992 \nL 160.713093 104.429865 \nL 160.827241 104.410581 \nL 160.964218 104.410334 \nL 161.124025 104.42905 \nL 161.283832 104.409761 \nL 161.489298 104.466212 \nL 161.649105 104.446929 \nL 161.831741 104.484297 \nL 161.968718 104.48396 \nL 162.242673 104.596121 \nL 162.40248 104.57678 \nL 162.539457 104.576328 \nL 162.744923 104.519488 \nL 162.881901 104.51911 \nL 162.973219 104.556214 \nL 163.155855 104.592941 \nL 163.247173 104.629888 \nL 163.361321 104.610841 \nL 163.498299 104.610347 \nL 163.703765 104.665268 \nL 163.863571 104.646085 \nL 163.95489 104.608707 \nL 164.365822 104.385962 \nL 164.479969 104.367368 \nL 164.708265 104.293531 \nL 165.050708 104.458232 \nL 165.233345 104.421243 \nL 165.621447 104.621077 \nL 165.735595 104.638872 \nL 165.872572 104.638352 \nL 165.963891 104.674358 \nL 166.123697 104.691854 \nL 166.260675 104.69127 \nL 166.48897 104.762657 \nL 166.694436 104.707494 \nL 166.854243 104.724826 \nL 167.059709 104.66991 \nL 167.493471 104.901219 \nL 167.676107 104.864319 \nL 167.835914 104.881279 \nL 168.087039 104.79064 \nL 168.246846 104.807642 \nL 168.406653 104.789032 \nL 168.54363 104.788343 \nL 168.771926 104.716305 \nL 168.908903 104.715705 \nL 169.09154 104.679557 \nL 169.205687 104.661441 \nL 169.342665 104.66091 \nL 169.456813 104.642852 \nL 169.685108 104.571676 \nL 169.867745 104.606226 \nL 170.027551 104.588157 \nL 170.164529 104.58772 \nL 170.369995 104.569583 \nL 170.506972 104.569168 \nL 170.712438 104.55112 \nL 170.940734 104.585255 \nL 171.214688 104.514983 \nL 171.534302 104.617996 \nL 171.739768 104.600022 \nL 171.945234 104.616598 \nL 172.333337 104.460608 \nL 172.65295 104.562791 \nL 172.812757 104.57944 \nL 173.063882 104.629914 \nL 173.246519 104.629283 \nL 173.383496 104.594739 \nL 173.566133 104.59416 \nL 173.70311 104.559753 \nL 173.931405 104.525192 \nL 174.182531 104.575303 \nL 174.365167 104.574762 \nL 174.547803 104.574215 \nL 174.913076 104.438607 \nL 175.141372 104.471759 \nL 175.460986 104.370654 \nL 175.712111 104.420454 \nL 175.849088 104.453601 \nL 176.123043 104.519662 \nL 176.305679 104.51921 \nL 176.556804 104.568353 \nL 176.716611 104.584461 \nL 176.853589 104.550957 \nL 177.013395 104.567049 \nL 177.31018 104.648635 \nL 177.492816 104.647993 \nL 177.721112 104.680062 \nL 177.926578 104.662887 \nL 178.086385 104.645927 \nL 178.497317 104.481237 \nL 178.725612 104.513348 \nL 178.999567 104.447655 \nL 179.136544 104.414919 \nL 179.36484 104.38213 \nL 179.501817 104.349562 \nL 179.684454 104.349373 \nL 179.88992 104.365307 \nL 180.072556 104.365092 \nL 180.300852 104.397013 \nL 180.597636 104.316321 \nL 180.89442 104.396177 \nL 181.145545 104.347874 \nL 181.351011 104.363625 \nL 181.487988 104.395346 \nL 181.94458 104.585318 \nL 182.150046 104.568868 \nL 182.492489 104.678632 \nL 182.697955 104.662104 \nL 182.94908 104.708514 \nL 183.131716 104.707814 \nL 183.314353 104.70712 \nL 183.45133 104.73799 \nL 183.702455 104.78398 \nL 183.95358 104.735972 \nL 184.273194 104.828276 \nL 184.410172 104.858794 \nL 184.615638 104.873335 \nL 184.843933 104.841125 \nL 185.049399 104.85565 \nL 185.186376 104.885952 \nL 185.391842 104.900367 \nL 185.711456 104.806149 \nL 186.03107 104.897039 \nL 186.213706 104.896098 \nL 186.350684 104.864692 \nL 186.55615 104.848358 \nL 186.807275 104.893049 \nL 187.012741 104.876726 \nL 187.355184 104.981658 \nL 187.58348 104.949931 \nL 187.788946 104.963984 \nL 187.948753 104.978252 \nL 188.199878 105.022233 \nL 188.496662 104.944932 \nL 188.679298 104.943938 \nL 188.930424 104.897418 \nL 189.227208 104.971023 \nL 189.478333 104.924639 \nL 189.797947 105.012707 \nL 190.231708 104.846166 \nL 190.345856 104.80095 \nL 190.551322 104.785194 \nL 190.962254 104.931768 \nL 191.14489 104.930811 \nL 191.327527 104.92986 \nL 191.578652 104.88427 \nL 191.829777 104.927252 \nL 192.058073 104.89665 \nL 192.17222 104.851996 \nL 192.332027 104.865938 \nL 192.514664 104.865081 \nL 192.6973 104.864224 \nL 192.902766 104.877882 \nL 193.153891 104.832908 \nL 193.382187 104.861028 \nL 193.564823 104.860187 \nL 193.770289 104.873766 \nL 193.930096 104.887524 \nL 194.135562 104.901024 \nL 194.432346 104.827277 \nL 194.592153 104.812142 \nL 194.888938 104.738826 \nL 195.048744 104.723838 \nL 195.25421 104.708724 \nL 195.619483 104.822146 \nL 196.030415 104.677439 \nL 196.3272 104.7478 \nL 196.441347 104.790136 \nL 196.623984 104.7894 \nL 196.82945 104.774359 \nL 197.103404 104.830037 \nL 197.286041 104.829254 \nL 197.537166 104.870612 \nL 197.788291 104.827109 \nL 197.948098 104.812326 \nL 198.107905 104.825748 \nL 198.290541 104.824975 \nL 198.518837 104.795919 \nL 198.724303 104.809124 \nL 198.952598 104.780179 \nL 199.112405 104.765569 \nL 199.340701 104.736771 \nL 199.660315 104.819239 \nL 199.865781 104.804477 \nL 200.162565 104.872715 \nL 200.368031 104.857926 \nL 200.619156 104.898354 \nL 200.824622 104.883576 \nL 201.030088 104.896445 \nL 201.281213 104.853936 \nL 201.44102 104.839479 \nL 201.600827 104.852554 \nL 201.783463 104.851765 \nL 201.988929 104.837166 \nL 202.377032 104.958648 \nL 202.742305 104.847659 \nL 203.221725 105.022438 \nL 203.564169 104.925601 \nL 203.906612 105.018742 \nL 204.066419 105.031406 \nL 204.317544 105.070546 \nL 204.454521 105.096742 \nL 204.614328 105.082327 \nL 204.842624 105.054107 \nL 205.02526 105.053092 \nL 205.207897 105.052077 \nL 205.413363 105.064342 \nL 205.755806 104.968815 \nL 206.029761 105.020845 \nL 206.235227 105.00643 \nL 206.349375 104.965876 \nL 206.57767 104.938155 \nL 206.920113 105.029419 \nL 207.171239 104.98834 \nL 207.422364 105.026749 \nL 207.582171 105.039113 \nL 207.810466 105.064274 \nL 208.289887 104.890673 \nL 208.541012 104.928961 \nL 208.974773 104.782949 \nL 209.203069 104.808262 \nL 209.522683 104.728769 \nL 209.705319 104.72817 \nL 209.887956 104.727571 \nL 210.002103 104.688179 \nL 210.344547 104.596311 \nL 210.618501 104.647462 \nL 210.846797 104.620967 \nL 211.075093 104.646211 \nL 211.280559 104.632753 \nL 211.531684 104.670725 \nL 211.828468 104.6056 \nL 211.942616 104.566787 \nL 212.193741 104.527763 \nL 212.399207 104.54017 \nL 212.581843 104.539796 \nL 212.74165 104.526696 \nL 213.221071 104.360139 \nL 213.563514 104.448827 \nL 213.883128 104.397617 \nL 214.111423 104.397365 \nL 214.499526 104.308467 \nL 214.978947 104.446798 \nL 215.230072 104.433865 \nL 215.412708 104.408489 \nL 215.618174 104.420796 \nL 215.869299 104.433014 \nL 216.257402 104.344999 \nL 216.462868 104.332355 \nL 216.759652 104.294767 \nL 217.010777 104.307095 \nL 217.35322 104.244829 \nL 217.581516 104.244798 \nL 217.8783 104.207625 \nL 218.220743 104.269396 \nL 218.471869 104.256989 \nL 218.677335 104.24463 \nL 218.90563 104.244598 \nL 219.088267 104.22 \nL 219.293733 104.23227 \nL 219.45354 104.195491 \nL 219.613346 104.232244 \nL 219.841642 104.232228 \nL 220.092767 104.22 \nL 220.389551 104.256563 \nL 220.731995 104.195681 \nL 221.005949 104.22 \nL 221.257074 104.207877 \nL 221.576688 104.2563 \nL 221.850643 104.232081 \nL 222.124598 104.25618 \nL 222.352893 104.256132 \nL 222.626848 104.280121 \nL 222.946462 104.232002 \nL 223.083439 104.18402 \nL 223.334564 104.172108 \nL 223.471541 104.124289 \nL 223.791155 104.076701 \nL 224.156428 104.148503 \nL 224.361894 104.160489 \nL 224.727167 104.231876 \nL 225.023951 104.19629 \nL 225.297906 104.22 \nL 225.59469 104.184556 \nL 225.868645 104.208203 \nL 226.09694 104.208224 \nL 226.507872 104.302264 \nL 226.713338 104.313903 \nL 226.895975 104.290356 \nL 227.1471 104.278543 \nL 227.329736 104.255086 \nL 227.64935 104.208329 \nL 227.831986 104.185019 \nL 228.083112 104.173422 \nL 228.357066 104.196742 \nL 228.67668 104.150364 \nL 228.950635 104.173653 \nL 229.20176 104.162151 \nL 229.567033 104.231545 \nL 229.977965 104.139366 \nL 230.20626 104.139471 \nL 230.411726 104.151058 \nL 230.73134 104.197058 \nL 230.959636 104.197089 \nL 231.302079 104.254298 \nL 231.667352 104.185776 \nL 232.055454 104.265532 \nL 232.329409 104.242732 \nL 232.557704 104.2427 \nL 232.786 104.242674 \nL 233.082784 104.276588 \nL 233.356739 104.253903 \nL 233.607864 104.265138 \nL 233.950307 104.208739 \nL 234.201432 104.22 \nL 234.452558 104.208771 \nL 234.680853 104.208781 \nL 234.909149 104.208802 \nL 235.114615 104.197615 \nL 235.525547 104.10836 \nL 235.753842 104.108496 \nL 235.913649 104.142016 \nL 236.141945 104.14211 \nL 236.415899 104.120009 \nL 236.575706 104.086805 \nL 236.804002 104.086963 \nL 237.123616 104.13147 \nL 237.351911 104.131575 \nL 237.557377 104.12064 \nL 237.831332 104.098739 \nL 238.150946 104.142973 \nL 238.379241 104.143067 \nL 238.630366 104.154149 \nL 238.97281 104.099496 \nL 239.497889 104.241849 \nL 239.794674 104.209097 \nL 240.091458 104.24178 \nL 240.319753 104.241749 \nL 240.548049 104.241722 \nL 240.707856 104.274264 \nL 240.936151 104.274196 \nL 241.164447 104.274133 \nL 241.52972 104.338853 \nL 241.758015 104.338706 \nL 242.077629 104.381599 \nL 242.420073 104.327535 \nL 242.694027 104.348852 \nL 242.899493 104.35944 \nL 243.104959 104.348574 \nL 243.378914 104.326988 \nL 243.675698 104.358862 \nL 243.926823 104.348011 \nL 244.155119 104.347859 \nL 244.451903 104.315743 \nL 244.703028 104.326241 \nL 244.885665 104.347364 \nL 245.068301 104.326036 \nL 245.456403 104.251748 \nL 245.935824 104.367773 \nL 246.301097 104.304282 \nL 246.597881 104.335704 \nL 246.871836 104.314534 \nL 247.008813 104.272482 \nL 247.442575 104.178111 \nL 247.716529 104.199087 \nL 248.058973 104.146926 \nL 248.332927 104.167881 \nL 248.515564 104.188752 \nL 248.6982 104.167975 \nL 248.926496 104.168039 \nL 249.063473 104.126539 \nL 249.291769 104.126644 \nL 249.679871 104.199297 \nL 249.862508 104.22 \nL 250.090803 104.22 \nL 250.456076 104.158134 \nL 250.661542 104.147904 \nL 251.003985 104.096615 \nL 251.369258 104.158418 \nL 251.529065 104.189235 \nL 251.848679 104.230236 \nL 252.076975 104.230225 \nL 252.373759 104.260843 \nL 252.784691 104.179247 \nL 253.195623 104.260674 \nL 253.720703 104.128726 \nL 254.085975 104.189635 \nL 254.314271 104.209885 \nL 254.679544 104.250276 \nL 254.976328 104.240156 \nL 255.227453 104.230067 \nL 255.638385 104.169773 \nL 256.003658 104.209969 \nL 256.231954 104.230015 \nL 256.551567 104.249997 \nL 257.008159 104.17012 \nL 257.213625 104.14027 \nL 257.556068 104.110557 \nL 257.921341 104.15048 \nL 258.240955 104.130755 \nL 258.606227 104.170509 \nL 259.039989 104.101483 \nL 259.473751 104.17072 \nL 260.090149 104.023478 \nL 260.295615 103.994227 \nL 260.569569 103.994522 \nL 260.980501 104.053675 \nL 261.140308 104.102682 \nL 261.528411 104.151699 \nL 261.779536 104.16152 \nL 262.07632 104.17134 \nL 262.6014 104.064683 \nL 262.898184 104.074598 \nL 263.263457 104.036148 \nL 263.446093 103.997634 \nL 263.742878 103.988297 \nL 264.13098 104.036915 \nL 264.473423 104.008348 \nL 264.907185 104.075997 \nL 265.226799 104.057039 \nL 265.500753 104.05725 \nL 265.843197 104.02884 \nL 266.094322 104.019525 \nL 266.505254 103.962748 \nL 266.802038 103.972621 \nL 267.053163 103.98242 \nL 267.349947 103.99224 \nL 267.760879 103.935852 \nL 268.080493 103.955188 \nL 268.377277 103.946114 \nL 268.651232 103.946472 \nL 268.925187 103.946819 \nL 269.176312 103.937734 \nL 269.495926 103.919366 \nL 269.815539 103.938575 \nL 270.066664 103.948269 \nL 270.386278 103.967384 \nL 270.637403 103.977026 \nL 271.025506 104.024109 \nL 271.29946 104.024351 \nL 271.596245 104.033929 \nL 271.915858 104.015613 \nL 272.144154 103.997276 \nL 272.395279 104.006802 \nL 272.646404 103.997792 \nL 272.920359 103.998065 \nL 273.285632 104.03537 \nL 273.582416 104.026401 \nL 273.8792 104.035864 \nL 274.107496 104.054453 \nL 274.472769 104.091453 \nL 274.860871 104.045852 \nL 275.111996 104.036894 \nL 275.363121 104.046252 \nL 275.682735 104.064767 \nL 275.911031 104.083167 \nL 276.367622 104.156273 \nL 276.801383 104.092809 \nL 277.235145 104.156525 \nL 277.5091 104.15661 \nL 277.737395 104.138578 \nL 278.102668 104.102577 \nL 278.376623 104.102724 \nL 278.878873 104.012974 \nL 279.107169 103.995205 \nL 279.403953 103.98652 \nL 279.906203 104.076649 \nL 280.271476 104.0411 \nL 280.750897 104.121807 \nL 281.07051 104.104122 \nL 281.367295 104.113175 \nL 281.59559 104.13107 \nL 282.166329 104.246612 \nL 282.577261 104.193441 \nL 282.896875 104.211158 \nL 283.12517 104.228832 \nL 283.467614 104.290561 \nL 283.467614 104.290561 \n\" clip-path=\"url(#pfb46636bbe)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path d=\"M 55.194886 192.42 \nL 55.286205 51.299998 \nL 55.331864 66.419997 \nL 55.354693 60.12 \nL 55.377523 74.819996 \nL 55.423182 96.201815 \nL 55.491671 79.020002 \nL 55.5145 74.819996 \nL 55.53733 82.17 \nL 55.674307 104.22 \nL 55.697137 100.385218 \nL 55.742796 93.636 \nL 55.811284 97.920003 \nL 55.948262 114.59647 \nL 55.993921 114.019999 \nL 56.245046 94.837022 \nL 56.56466 114.34131 \nL 56.838614 103.011785 \nL 57.04408 108.52244 \nL 57.06691 107.40795 \nL 57.112569 109.408235 \nL 57.135399 108.322328 \nL 57.226717 110.1 \nL 57.181058 108.229092 \nL 57.272376 109.972173 \nL 57.386524 106.947835 \nL 57.409353 107.819998 \nL 57.500671 109.408235 \nL 57.455012 107.748002 \nL 57.523501 108.501554 \nL 57.546331 107.61231 \nL 57.59199 109.212454 \nL 57.614819 108.341495 \nL 57.843115 112.512307 \nL 58.002922 109.910322 \nL 58.025751 110.570402 \nL 58.07141 109.081415 \nL 58.117069 107.638606 \nL 58.185558 108.229092 \nL 58.231217 109.485673 \nL 58.299706 108.726569 \nL 58.368195 109.26 \nL 58.413854 107.946758 \nL 58.642149 113.504212 \nL 58.710638 112.755486 \nL 58.733467 113.266153 \nL 58.779127 112.035191 \nL 58.824786 113.040002 \nL 58.916104 110.673658 \nL 58.961763 111.658555 \nL 59.030252 113.09219 \nL 59.075911 111.956844 \nL 59.12157 110.847747 \nL 59.167229 111.78 \nL 59.395525 114.231893 \nL 59.418354 113.703872 \nL 59.464013 114.541275 \nL 59.486843 114.953334 \nL 59.532502 113.91738 \nL 59.737968 111.275999 \nL 59.760798 111.679704 \nL 59.806457 110.737243 \nL 59.829286 111.137647 \nL 59.874945 110.214174 \nL 59.943434 110.550141 \nL 60.011923 110.044526 \nL 60.103241 111.569998 \nL 60.331536 108.122656 \nL 60.354366 108.49401 \nL 60.377196 108.862103 \nL 60.422855 108.054782 \nL 60.468514 108.782069 \nL 60.605491 107.184706 \nL 60.628321 107.541339 \nL 60.65115 107.895002 \nL 60.719639 107.486665 \nL 60.993594 104.565882 \nL 61.19906 106.224544 \nL 61.221889 105.88415 \nL 61.267548 106.532359 \nL 61.290378 106.852834 \nL 61.336037 106.18 \nL 61.381696 106.81412 \nL 61.518673 106.123596 \nL 61.632821 107.648269 \nL 61.67848 107.005264 \nL 61.906776 105.11695 \nL 61.952435 105.70485 \nL 61.998094 105.104948 \nL 62.272049 102.801994 \nL 62.294878 103.089233 \nL 62.340537 102.534648 \nL 62.363367 102.259995 \nL 62.409026 102.828837 \nL 62.454685 102.284577 \nL 62.568833 103.675551 \nL 62.614492 103.137788 \nL 62.637322 102.871378 \nL 62.682981 103.415743 \nL 62.774299 103.955135 \nL 62.797128 103.691858 \nL 62.865617 102.911395 \nL 62.934106 103.182348 \nL 62.956935 103.444048 \nL 63.002594 102.934285 \nL 63.139572 101.440061 \nL 63.20806 101.714315 \nL 63.367867 102.500225 \nL 63.390697 102.259995 \nL 63.436356 102.758118 \nL 63.710311 105.163313 \nL 63.73314 104.925601 \nL 63.892947 103.758224 \nL 63.915777 103.989717 \nL 63.961436 104.44909 \nL 64.029924 104.22 \nL 64.144072 103.995573 \nL 64.166902 104.22 \nL 64.212561 103.774542 \nL 64.349538 103.342385 \nL 64.486516 103.787643 \nL 64.555004 103.576201 \nL 64.577834 103.791849 \nL 64.600663 104.006445 \nL 64.646322 103.582405 \nL 64.714811 103.375978 \nL 64.737641 103.588493 \nL 64.828959 104.011492 \nL 64.851788 103.803961 \nL 64.943107 102.983555 \nL 65.034425 102.995005 \nL 65.148573 103.210852 \nL 65.217061 102.616365 \nL 65.28555 102.826324 \nL 65.376868 103.233426 \nL 65.399698 103.038755 \nL 65.445357 102.651998 \nL 65.513846 102.857089 \nL 65.742141 104.029503 \nL 65.879118 103.279699 \nL 65.901948 103.469366 \nL 66.038925 104.590591 \nL 66.084584 104.22 \nL 66.153073 104.036631 \nL 66.175903 104.22 \nL 66.198732 104.402606 \nL 66.244391 104.038145 \nL 66.267221 104.22 \nL 66.427028 103.683289 \nL 66.609664 104.396046 \nL 66.678153 104.569999 \nL 66.723812 104.22 \nL 66.952108 105.245582 \nL 67.089085 104.895862 \nL 67.157574 105.06 \nL 67.180403 104.89072 \nL 67.203233 104.722087 \nL 67.248892 105.053649 \nL 67.271721 104.885658 \nL 67.34021 105.378351 \nL 67.408699 105.207315 \nL 67.477187 105.038183 \nL 67.500017 105.200003 \nL 67.568506 105.032153 \nL 67.659824 105.671189 \nL 67.728312 105.502908 \nL 67.751142 105.660653 \nL 67.773972 105.817826 \nL 67.819631 105.493645 \nL 67.910949 105.168386 \nL 67.933778 105.32447 \nL 67.956608 105.480003 \nL 68.002267 105.161636 \nL 68.253392 104.066071 \nL 68.321881 103.913751 \nL 68.413199 104.524135 \nL 68.550176 104.22 \nL 68.664324 104.667718 \nL 68.687154 104.517974 \nL 68.755642 104.368235 \nL 68.778472 104.515971 \nL 68.915449 105.099071 \nL 68.938279 104.951346 \nL 69.006768 105.093267 \nL 69.052427 104.800261 \nL 69.120915 105.230473 \nL 69.189404 105.081891 \nL 69.212234 104.937072 \nL 69.257893 105.220647 \nL 69.280722 105.361749 \nL 69.326381 105.073548 \nL 69.349211 105.214202 \nL 69.39487 104.927867 \nL 69.463359 105.065367 \nL 69.486188 105.204687 \nL 69.531847 104.921112 \nL 69.760143 104.081969 \nL 69.89712 104.630235 \nL 69.91995 104.493066 \nL 69.942779 104.356323 \nL 69.988438 104.627706 \nL 70.171075 105.42822 \nL 70.193904 105.292339 \nL 70.216734 105.156873 \nL 70.262393 105.420907 \nL 70.285223 105.552325 \nL 70.330882 105.28265 \nL 70.353711 105.413684 \nL 70.673325 104.090107 \nL 70.696155 104.22 \nL 70.741814 103.961349 \nL 70.764643 104.090864 \nL 71.061428 102.952758 \nL 71.084257 103.081116 \nL 71.129916 102.832013 \nL 71.175575 102.584339 \nL 71.244064 102.716587 \nL 71.312553 103.097224 \nL 71.358212 102.85159 \nL 71.563678 102.254538 \nL 71.791973 103.008463 \nL 72.043098 102.191042 \nL 72.157246 102.560324 \nL 72.180076 102.444163 \nL 72.385542 101.880483 \nL 72.49969 102.01209 \nL 72.591008 101.56128 \nL 72.636667 101.798818 \nL 72.796474 102.163527 \nL 72.819303 102.052086 \nL 72.864962 102.285292 \nL 72.887792 102.174125 \nL 73.138917 102.987214 \nL 73.161747 102.876856 \nL 73.207406 103.103543 \nL 73.230235 103.216456 \nL 73.275894 102.99654 \nL 73.412872 102.784961 \nL 73.48136 102.680344 \nL 73.549849 103.014782 \nL 73.618338 103.12842 \nL 73.663997 102.91333 \nL 73.823804 103.248398 \nL 74.00644 102.830183 \nL 74.097758 103.049679 \nL 74.120588 102.94482 \nL 74.189077 103.055293 \nL 74.234736 102.846827 \nL 74.348884 103.170004 \nL 74.371713 103.066375 \nL 74.394543 102.962989 \nL 74.440202 103.174977 \nL 74.691327 103.910523 \nL 74.714156 103.807852 \nL 74.759816 104.014404 \nL 74.828304 103.912679 \nL 74.873963 104.117801 \nL 74.988111 103.81355 \nL 75.010941 103.915507 \nL 75.102259 104.118968 \nL 75.125088 104.018168 \nL 75.284895 103.519204 \nL 75.307725 103.620004 \nL 75.444702 103.822698 \nL 75.695827 103.140806 \nL 75.809975 103.439474 \nL 75.832805 103.342869 \nL 76.015441 102.964145 \nL 76.0611 103.159668 \nL 76.106759 102.969623 \nL 76.198078 102.783521 \nL 76.220907 102.880736 \nL 76.540521 103.843074 \nL 76.58618 103.655826 \nL 76.631839 103.844683 \nL 76.654669 103.938807 \nL 76.700328 103.752347 \nL 76.745987 103.566665 \nL 76.814476 103.661777 \nL 76.860135 103.848636 \nL 76.928623 103.757246 \nL 76.997112 103.666445 \nL 77.019942 103.759181 \nL 77.11126 103.944663 \nL 77.134089 103.853263 \nL 77.293896 103.400803 \nL 77.316726 103.492581 \nL 77.339555 103.584161 \nL 77.385214 103.404178 \nL 77.408044 103.495568 \nL 77.61351 103.053569 \nL 77.750487 103.417373 \nL 77.773317 103.329095 \nL 77.796146 103.240986 \nL 77.841806 103.420601 \nL 77.910294 103.688672 \nL 77.978783 103.601982 \nL 78.13859 103.167912 \nL 78.161419 103.256547 \nL 78.252738 103.434837 \nL 78.275567 103.348463 \nL 78.389715 103.092566 \nL 78.412544 103.180318 \nL 78.503863 103.35699 \nL 78.526692 103.271614 \nL 78.686499 103.021164 \nL 78.846306 103.28442 \nL 78.891965 103.116434 \nL 78.937624 103.288016 \nL 78.983283 103.458925 \nL 79.028942 103.29158 \nL 79.188749 103.046241 \nL 79.257238 102.965975 \nL 79.325727 103.219621 \nL 79.417045 102.891187 \nL 79.462704 103.059478 \nL 79.485534 103.143382 \nL 79.531193 102.980074 \nL 79.554022 103.063821 \nL 79.713829 102.82521 \nL 79.850807 103.322503 \nL 79.896466 103.161277 \nL 79.919295 103.080885 \nL 79.964954 103.245412 \nL 80.010613 103.40934 \nL 80.056273 103.248987 \nL 80.079102 103.169037 \nL 80.124761 103.332355 \nL 80.147591 103.413788 \nL 80.19325 103.254307 \nL 80.216079 103.335593 \nL 80.398716 103.02271 \nL 80.467205 103.264769 \nL 80.512864 103.10757 \nL 80.741159 102.644995 \nL 80.923796 103.125318 \nL 80.946625 103.048165 \nL 80.969455 102.971148 \nL 81.015114 103.129188 \nL 81.037943 103.052307 \nL 81.060773 103.131112 \nL 81.106432 102.977751 \nL 81.357557 102.451386 \nL 81.403216 102.607985 \nL 81.448875 102.457537 \nL 81.585853 102.009282 \nL 81.631512 102.165293 \nL 81.768489 102.327297 \nL 81.814148 102.179382 \nL 81.882637 102.259995 \nL 81.951126 102.490583 \nL 82.019614 102.420001 \nL 82.065273 102.273306 \nL 82.110933 102.426099 \nL 82.22508 102.5081 \nL 82.362058 102.220503 \nL 82.384887 102.296174 \nL 82.453376 102.227201 \nL 82.544694 102.528087 \nL 82.681671 102.390119 \nL 82.818649 102.544858 \nL 82.864308 102.40219 \nL 82.909967 102.550367 \nL 83.024115 102.918692 \nL 83.069774 102.776466 \nL 83.092603 102.705526 \nL 83.138263 102.852 \nL 83.320899 103.290077 \nL 83.343729 103.219347 \nL 83.526365 102.941739 \nL 83.572024 103.085596 \nL 83.617683 102.94584 \nL 83.731831 102.739424 \nL 83.754661 102.811058 \nL 83.891638 102.957994 \nL 83.937297 102.819995 \nL 84.005786 102.893164 \nL 84.119933 103.24618 \nL 84.165593 103.108822 \nL 84.256911 102.835388 \nL 84.30257 102.975795 \nL 84.416718 103.187216 \nL 84.439547 103.11922 \nL 84.576525 102.850434 \nL 84.599354 102.919922 \nL 84.690672 103.060372 \nL 84.713502 102.993102 \nL 84.850479 102.863072 \nL 85.033116 103.1411 \nL 85.170093 103.011785 \nL 85.238582 103.215447 \nL 85.284241 103.08323 \nL 85.444048 102.889683 \nL 85.466877 102.957153 \nL 85.512536 102.826324 \nL 85.535366 102.893689 \nL 85.695173 102.438853 \nL 85.740832 102.573246 \nL 85.946298 102.911395 \nL 86.106105 102.722875 \nL 86.174593 102.66124 \nL 86.220253 102.793236 \nL 86.288741 102.602245 \nL 86.3344 102.733841 \nL 86.35723 102.799503 \nL 86.402889 102.672627 \nL 86.585525 102.425237 \nL 86.676844 102.686085 \nL 86.722503 102.560661 \nL 86.768162 102.435604 \nL 86.813821 102.565455 \nL 86.905139 102.697125 \nL 86.927969 102.634807 \nL 87.042117 102.450944 \nL 87.064946 102.515344 \nL 87.201923 102.7741 \nL 87.224753 102.712308 \nL 87.293242 102.527467 \nL 87.338901 102.655058 \nL 87.521537 103.037356 \nL 87.544367 102.975995 \nL 87.681344 102.857363 \nL 87.863981 103.111345 \nL 87.88681 103.050562 \nL 87.932469 103.175124 \nL 88.320572 104.098508 \nL 88.343401 104.037893 \nL 88.366231 103.977362 \nL 88.41189 104.098844 \nL 88.434719 104.038398 \nL 88.548867 104.22 \nL 88.571697 104.159711 \nL 88.754333 103.920207 \nL 88.822822 103.86098 \nL 89.073947 104.51697 \nL 89.096777 104.457417 \nL 89.142436 104.575645 \nL 89.165265 104.63464 \nL 89.210924 104.515777 \nL 89.279413 104.574215 \nL 89.325072 104.45583 \nL 89.347902 104.514589 \nL 89.393561 104.396519 \nL 89.41639 104.455199 \nL 89.530538 104.161394 \nL 89.576197 104.278528 \nL 89.644686 104.453643 \nL 89.690345 104.336666 \nL 89.758834 104.394652 \nL 89.850152 104.16194 \nL 89.94147 104.277913 \nL 89.9643 104.22 \nL 90.215425 103.587946 \nL 90.283913 103.646531 \nL 90.352402 103.704875 \nL 90.375232 103.648014 \nL 90.512209 103.536279 \nL 90.672016 103.822961 \nL 90.694845 103.766531 \nL 90.786164 103.654617 \nL 90.808993 103.711478 \nL 90.877482 103.768854 \nL 90.900311 103.712782 \nL 90.945971 103.600857 \nL 90.99163 103.714075 \nL 91.037289 103.826998 \nL 91.082948 103.715358 \nL 91.151437 103.548423 \nL 91.197096 103.661062 \nL 91.219925 103.717282 \nL 91.265584 103.606335 \nL 91.288414 103.662481 \nL 91.379732 103.55266 \nL 91.402562 103.608659 \nL 91.49388 103.721067 \nL 91.516709 103.665983 \nL 91.585198 103.50113 \nL 91.630857 103.612486 \nL 91.699346 103.558495 \nL 91.745005 103.669442 \nL 91.790664 103.560146 \nL 91.836323 103.670809 \nL 91.950471 103.836755 \nL 91.973301 103.782281 \nL 91.99613 103.72787 \nL 92.041789 103.837712 \nL 92.064619 103.892523 \nL 92.110278 103.783911 \nL 92.201596 103.676224 \nL 92.224426 103.730908 \nL 92.338573 103.786581 \nL 92.475551 103.680219 \nL 92.566869 103.789231 \nL 92.589699 103.735682 \nL 92.612528 103.682196 \nL 92.658187 103.790282 \nL 92.795165 103.898884 \nL 92.840824 103.792364 \nL 92.886483 103.899662 \nL 93.02346 104.007212 \nL 93.114778 103.901586 \nL 93.137608 103.95482 \nL 93.160437 104.00798 \nL 93.206097 103.902354 \nL 93.228926 103.955451 \nL 93.343074 103.797989 \nL 93.365903 103.85096 \nL 93.411563 103.956712 \nL 93.480051 103.904625 \nL 93.571369 103.800502 \nL 93.594199 103.853157 \nL 93.639858 103.958279 \nL 93.685517 103.85402 \nL 93.868154 103.647614 \nL 94.005131 103.753335 \nL 94.07362 103.805917 \nL 94.187767 103.549085 \nL 94.301915 103.705411 \nL 94.324745 103.654291 \nL 94.347574 103.603213 \nL 94.393233 103.70661 \nL 94.416063 103.655605 \nL 94.484552 103.707808 \nL 94.507381 103.656909 \nL 94.57587 103.606787 \nL 94.598699 103.658213 \nL 94.758506 103.813077 \nL 94.918313 103.662734 \nL 95.283586 104.2702 \nL 95.420563 104.169973 \nL 95.489052 104.120115 \nL 95.534711 104.22 \nL 95.694518 104.070929 \nL 95.808666 104.22 \nL 95.831495 104.170478 \nL 95.877155 104.071602 \nL 95.945643 104.121229 \nL 96.014132 104.072096 \nL 96.10545 104.269191 \nL 96.219598 104.121891 \nL 96.242427 104.170972 \nL 96.356575 104.317783 \nL 96.379405 104.268865 \nL 96.562041 104.074052 \nL 96.721848 104.22 \nL 96.790337 104.171613 \nL 96.813166 104.22 \nL 96.972973 104.364513 \nL 97.041462 104.316184 \nL 97.064291 104.364198 \nL 97.201269 104.459541 \nL 97.315417 104.315559 \nL 97.338246 104.363257 \nL 97.475223 104.45799 \nL 97.589371 104.409882 \nL 97.726349 104.59854 \nL 97.749178 104.551047 \nL 97.954644 104.314129 \nL 98.000303 104.408058 \nL 98.045962 104.313929 \nL 98.091621 104.22 \nL 98.137281 104.313729 \nL 98.365576 104.592941 \nL 98.66236 104.173706 \nL 98.68519 104.22 \nL 98.730849 104.127548 \nL 98.799338 104.081538 \nL 98.822167 104.127737 \nL 98.981974 104.265963 \nL 99.233099 103.945799 \nL 99.278758 104.037388 \nL 99.324417 103.946366 \nL 99.347247 103.900934 \nL 99.392906 103.992324 \nL 99.575543 104.174652 \nL 99.598372 104.129357 \nL 99.644031 104.22 \nL 99.758179 104.445804 \nL 99.826668 104.400367 \nL 100.009304 104.22 \nL 100.123452 104.354383 \nL 100.146282 104.309545 \nL 100.306088 104.086164 \nL 100.328918 104.130818 \nL 100.374577 104.22 \nL 100.443066 104.175525 \nL 100.465895 104.131091 \nL 100.511554 104.22 \nL 100.580043 104.264344 \nL 100.602873 104.22 \nL 100.694191 104.131533 \nL 100.71702 104.175788 \nL 100.922486 104.484071 \nL 100.945316 104.439948 \nL 100.990975 104.351838 \nL 101.059464 104.39552 \nL 101.219271 104.613554 \nL 101.2421 104.569652 \nL 101.401907 104.437777 \nL 101.447566 104.524588 \nL 101.516055 104.480691 \nL 101.561714 104.393622 \nL 101.607373 104.480175 \nL 101.630203 104.523389 \nL 101.675862 104.436494 \nL 101.698691 104.479665 \nL 101.76718 104.349641 \nL 101.835669 104.392602 \nL 101.858498 104.435647 \nL 101.904157 104.349262 \nL 101.926987 104.306133 \nL 101.972646 104.392097 \nL 102.132453 104.6059 \nL 102.155282 104.562859 \nL 102.337919 104.390767 \nL 102.429237 104.475654 \nL 102.452067 104.43294 \nL 102.474896 104.390268 \nL 102.520555 104.47516 \nL 102.726021 104.685771 \nL 102.77168 104.600721 \nL 102.81734 104.684877 \nL 102.840169 104.726898 \nL 102.885828 104.642011 \nL 102.908658 104.683989 \nL 103.091294 104.514142 \nL 103.159783 104.471759 \nL 103.205442 104.555363 \nL 103.410908 104.345225 \nL 103.433738 104.386888 \nL 103.479397 104.303362 \nL 103.707692 104.054053 \nL 103.79901 104.22 \nL 103.84467 104.137263 \nL 103.935988 104.054832 \nL 103.958817 104.096184 \nL 104.141454 104.261121 \nL 104.34692 104.056209 \nL 104.438238 104.138262 \nL 104.461068 104.097446 \nL 104.575215 103.975449 \nL 104.598045 104.016307 \nL 104.735022 104.179373 \nL 104.757852 104.138788 \nL 104.803511 104.057723 \nL 104.84917 104.138935 \nL 104.986147 104.300844 \nL 105.008977 104.260401 \nL 105.123125 104.139377 \nL 105.145954 104.179709 \nL 105.282932 104.26018 \nL 105.305761 104.22 \nL 105.35142 104.300255 \nL 105.37425 104.260107 \nL 105.465568 104.34011 \nL 105.488398 104.300035 \nL 105.648204 104.180109 \nL 105.785182 104.259786 \nL 105.89933 104.140607 \nL 105.922159 104.180319 \nL 106.013477 104.259607 \nL 106.036307 104.22 \nL 106.196114 104.101609 \nL 106.310262 104.22 \nL 106.333091 104.180645 \nL 106.470068 104.10224 \nL 106.607046 104.180855 \nL 106.744023 104.102871 \nL 106.881 104.181055 \nL 107.086466 103.987277 \nL 107.223444 104.142636 \nL 107.246273 104.103996 \nL 107.383251 104.027168 \nL 107.520228 104.104606 \nL 107.565887 104.027841 \nL 107.611546 104.104806 \nL 107.771353 104.296565 \nL 107.794183 104.258267 \nL 107.817012 104.22 \nL 107.862671 104.296428 \nL 107.885501 104.334595 \nL 107.93116 104.258167 \nL 108.136626 104.067932 \nL 108.250774 104.106194 \nL 108.319262 104.068458 \nL 108.342092 104.106393 \nL 108.547558 104.29545 \nL 108.661706 104.182359 \nL 108.684535 104.22 \nL 108.844342 104.33255 \nL 108.93566 104.182548 \nL 108.98132 104.25742 \nL 109.118297 104.331977 \nL 109.163956 104.257294 \nL 109.209615 104.331788 \nL 109.346592 104.480175 \nL 109.369422 104.442913 \nL 109.392252 104.405682 \nL 109.437911 104.479739 \nL 109.711865 104.773786 \nL 109.780354 104.662477 \nL 109.826013 104.735788 \nL 109.917331 104.808488 \nL 109.940161 104.771478 \nL 110.099968 104.586585 \nL 110.122797 104.623075 \nL 110.168456 104.695965 \nL 110.214116 104.622407 \nL 110.328263 104.585066 \nL 110.396752 104.621077 \nL 110.419582 104.584461 \nL 110.5109 104.511087 \nL 110.533729 104.54734 \nL 110.716366 104.69127 \nL 110.899002 104.545196 \nL 111.104468 104.724001 \nL 111.195786 104.651295 \nL 111.218616 104.687049 \nL 111.332764 104.793658 \nL 111.355593 104.757589 \nL 111.675207 104.39818 \nL 111.698037 104.433734 \nL 111.743696 104.362374 \nL 111.835014 104.291071 \nL 111.857844 104.326562 \nL 111.880673 104.362027 \nL 111.926332 104.290955 \nL 112.06331 104.22 \nL 112.200287 104.361233 \nL 112.223116 104.325884 \nL 112.314435 104.255239 \nL 112.337264 104.290446 \nL 112.474242 104.36056 \nL 112.56556 104.290167 \nL 112.588389 104.325211 \nL 112.725367 104.394931 \nL 112.816685 104.394652 \nL 112.930833 104.429171 \nL 112.953662 104.394237 \nL 112.999321 104.463742 \nL 113.09064 104.463358 \nL 113.181958 104.462974 \nL 113.273276 104.462596 \nL 113.455912 104.323644 \nL 113.478742 104.358136 \nL 113.524401 104.289016 \nL 113.707038 104.151205 \nL 113.798356 104.22 \nL 113.821185 104.185671 \nL 114.003822 104.04887 \nL 114.140799 104.11756 \nL 114.186458 104.049396 \nL 114.232117 104.117717 \nL 114.369095 104.185986 \nL 114.460413 104.186039 \nL 114.528902 104.287849 \nL 114.574561 104.22 \nL 114.665879 104.084618 \nL 114.711538 104.152362 \nL 114.780027 104.186218 \nL 114.802856 104.152467 \nL 114.962663 104.051614 \nL 115.12247 104.152824 \nL 115.282277 104.052508 \nL 115.419254 104.119736 \nL 115.579061 104.019998 \nL 115.601891 104.053391 \nL 115.64755 103.98693 \nL 115.853016 103.755438 \nL 115.875845 103.788789 \nL 115.967164 103.789431 \nL 116.1498 103.658633 \nL 116.286777 103.791681 \nL 116.309607 103.758908 \nL 116.469414 103.661567 \nL 116.606391 103.728364 \nL 116.697709 103.663638 \nL 116.720539 103.696558 \nL 116.926005 103.926547 \nL 116.948834 103.894058 \nL 117.062982 103.731991 \nL 117.108641 103.797369 \nL 117.222789 103.830594 \nL 117.245619 103.798305 \nL 117.291278 103.86344 \nL 117.359766 103.960971 \nL 117.405426 103.896445 \nL 117.633721 103.704212 \nL 117.770698 103.834001 \nL 117.793528 103.801995 \nL 117.884846 103.738384 \nL 117.907676 103.770652 \nL 118.044653 103.835683 \nL 118.158801 103.804413 \nL 118.478415 104.124583 \nL 118.501244 104.09282 \nL 118.546903 104.156452 \nL 118.683881 104.22 \nL 118.820858 104.093461 \nL 118.843688 104.12513 \nL 118.889347 104.188394 \nL 118.957835 104.093734 \nL 119.117642 103.999579 \nL 119.300279 104.063001 \nL 119.437256 104.063338 \nL 119.528574 104.063558 \nL 119.551404 104.032341 \nL 119.779699 103.908336 \nL 120.099313 104.157976 \nL 120.28195 104.034444 \nL 120.304779 104.06543 \nL 120.601563 104.28155 \nL 120.738541 104.22 \nL 120.76137 104.250702 \nL 120.7842 104.281377 \nL 120.852689 104.18934 \nL 121.012495 104.158839 \nL 121.28645 104.341823 \nL 121.377768 104.341655 \nL 121.400598 104.372015 \nL 121.697382 104.58321 \nL 121.857189 104.552145 \nL 122.039825 104.611467 \nL 122.222462 104.490274 \nL 122.245291 104.520203 \nL 122.450757 104.609075 \nL 122.473587 104.579025 \nL 122.542076 104.668323 \nL 122.656223 104.6974 \nL 122.679053 104.667413 \nL 122.861689 104.606709 \nL 122.953008 104.665605 \nL 122.998667 104.605931 \nL 123.204133 104.515971 \nL 123.615065 104.867232 \nL 123.706383 104.80761 \nL 123.752042 104.865938 \nL 123.86619 104.835552 \nL 123.957508 104.776189 \nL 124.003167 104.834327 \nL 124.231463 105.065551 \nL 124.277122 105.006719 \nL 124.551077 104.829475 \nL 124.619565 104.857869 \nL 124.665224 104.799499 \nL 124.802202 104.68269 \nL 124.847861 104.740182 \nL 125.098986 104.882293 \nL 125.281622 104.823124 \nL 125.464259 104.993434 \nL 125.509918 104.935679 \nL 125.669725 104.905493 \nL 125.89802 105.01716 \nL 126.263293 104.729826 \nL 126.4231 104.756942 \nL 126.651396 104.642547 \nL 126.902521 104.781425 \nL 127.085157 104.724001 \nL 127.153646 104.751496 \nL 127.199305 104.695245 \nL 127.427601 104.582274 \nL 127.541748 104.609527 \nL 127.564578 104.581591 \nL 127.701555 104.580907 \nL 127.929851 104.690476 \nL 128.043999 104.606841 \nL 128.089658 104.66183 \nL 128.272294 104.715816 \nL 128.295124 104.688121 \nL 128.363612 104.770216 \nL 128.614737 104.905419 \nL 128.774544 104.876573 \nL 128.888692 104.902875 \nL 128.911522 104.875354 \nL 129.00284 104.820001 \nL 129.048499 104.874139 \nL 129.162647 104.900346 \nL 129.185476 104.87293 \nL 129.231135 104.818151 \nL 129.299624 104.89909 \nL 129.413772 104.979408 \nL 129.459431 104.924734 \nL 129.550749 104.923867 \nL 129.573579 104.950715 \nL 129.664897 104.949821 \nL 129.687727 104.922573 \nL 129.847533 104.894106 \nL 130.03017 105.053854 \nL 130.075829 104.99958 \nL 130.098659 104.972469 \nL 130.167147 105.05233 \nL 130.326954 105.077354 \nL 130.509591 104.968363 \nL 130.53242 104.994854 \nL 130.55525 105.021334 \nL 130.623738 104.940542 \nL 130.943352 104.724911 \nL 131.171648 104.935348 \nL 131.217307 104.881962 \nL 131.240136 104.855293 \nL 131.308625 104.934065 \nL 131.445602 104.98558 \nL 131.468432 104.958958 \nL 131.673898 104.878014 \nL 131.696727 104.904131 \nL 131.765216 104.824649 \nL 131.947853 104.718308 \nL 131.970682 104.744378 \nL 132.039171 104.770106 \nL 132.08483 104.717419 \nL 132.267466 104.664001 \nL 132.518591 104.792727 \nL 132.632739 104.76589 \nL 132.655569 104.791713 \nL 132.838205 104.842223 \nL 133.066501 104.736997 \nL 133.180649 104.710432 \nL 133.363285 104.657782 \nL 133.523092 104.733984 \nL 133.545921 104.708146 \nL 133.751387 104.629993 \nL 133.979683 104.782108 \nL 134.002513 104.756401 \nL 134.344956 104.525192 \nL 134.459104 104.550148 \nL 134.481933 104.524661 \nL 134.64174 104.448039 \nL 134.66457 104.473304 \nL 134.801547 104.472868 \nL 135.029843 104.371284 \nL 135.189649 104.446477 \nL 135.212479 104.421253 \nL 135.509263 104.194934 \nL 135.532093 104.22 \nL 135.554922 104.24505 \nL 135.623411 104.169942 \nL 135.714729 104.119999 \nL 135.760388 104.170026 \nL 135.943025 104.22 \nL 136.239809 104.046136 \nL 136.376786 104.046431 \nL 136.490934 104.071434 \nL 136.673571 104.170583 \nL 136.6964 104.145906 \nL 136.71923 104.121229 \nL 136.787718 104.195334 \nL 136.924696 104.293889 \nL 136.970355 104.244614 \nL 137.175821 104.170888 \nL 137.289969 104.244519 \nL 137.335628 104.195491 \nL 137.472605 104.1466 \nL 137.495435 104.171077 \nL 137.655241 104.195586 \nL 137.74656 104.098077 \nL 137.815048 104.171266 \nL 137.997685 104.22 \nL 138.180321 104.171487 \nL 138.385787 104.244199 \nL 138.682571 104.075334 \nL 138.819549 104.12371 \nL 138.842378 104.099675 \nL 138.979356 104.099864 \nL 139.25331 104.243946 \nL 139.321799 104.22 \nL 139.367458 104.267829 \nL 139.390288 104.291728 \nL 139.458776 104.22 \nL 139.572924 104.196143 \nL 139.595754 104.22 \nL 139.687072 104.22 \nL 139.709902 104.196185 \nL 140.006686 103.982651 \nL 140.029515 104.006445 \nL 140.120834 104.006666 \nL 140.143663 103.98303 \nL 140.257811 103.959688 \nL 140.28064 103.983408 \nL 140.417618 104.031038 \nL 140.440447 104.007465 \nL 140.577425 104.007812 \nL 140.714402 104.008148 \nL 140.782891 103.984796 \nL 140.82855 104.031942 \nL 141.011186 104.126171 \nL 141.034016 104.102745 \nL 141.102504 104.079403 \nL 141.148164 104.126318 \nL 141.376459 104.22 \nL 141.399289 104.196648 \nL 141.467777 104.266668 \nL 141.581925 104.243305 \nL 141.83305 104.127064 \nL 141.85588 104.150311 \nL 141.924368 104.080739 \nL 142.107005 104.034707 \nL 142.221153 104.011818 \nL 142.312471 104.012038 \nL 142.3353 104.035191 \nL 142.35813 104.058333 \nL 142.426619 103.989233 \nL 142.586426 103.966617 \nL 142.677744 104.012901 \nL 142.723403 103.967016 \nL 143.043017 103.784615 \nL 143.157164 103.85383 \nL 143.202824 103.808283 \nL 143.453949 103.695412 \nL 143.636585 103.742011 \nL 144.024688 103.494821 \nL 144.230154 103.56432 \nL 144.321472 103.610162 \nL 144.481279 103.633798 \nL 144.686745 103.567664 \nL 144.846552 103.591279 \nL 145.120506 103.458883 \nL 145.234654 103.437487 \nL 145.348802 103.460807 \nL 145.645586 103.619089 \nL 145.851052 103.553838 \nL 146.170666 103.7332 \nL 146.376132 103.668064 \nL 146.49028 103.646699 \nL 146.672916 103.603833 \nL 146.809893 103.604758 \nL 147.015359 103.540358 \nL 147.243655 103.629519 \nL 147.426291 103.587042 \nL 147.677416 103.697589 \nL 147.905712 103.612023 \nL 148.225326 103.787223 \nL 148.407962 103.744882 \nL 148.636258 103.832213 \nL 148.796065 103.811363 \nL 148.910212 103.790387 \nL 149.001531 103.833727 \nL 149.161338 103.855807 \nL 149.298315 103.856333 \nL 149.435292 103.856859 \nL 149.595099 103.836156 \nL 149.823395 103.922173 \nL 149.937542 103.94378 \nL 150.143008 104.00798 \nL 150.234327 104.050552 \nL 150.462622 104.135476 \nL 150.668088 104.072401 \nL 150.827895 104.093703 \nL 150.987702 104.072895 \nL 151.124679 104.073105 \nL 151.398634 103.947975 \nL 151.558441 103.969309 \nL 151.763907 103.907306 \nL 151.992202 103.991231 \nL 152.083521 104.033004 \nL 152.197668 104.01247 \nL 152.288987 104.054138 \nL 152.425964 104.054369 \nL 152.65426 103.972126 \nL 152.814066 103.993155 \nL 152.996703 103.952412 \nL 153.15651 103.973399 \nL 153.384805 103.891966 \nL 153.498953 103.871873 \nL 153.63593 103.872357 \nL 153.772908 103.87284 \nL 153.955544 103.832707 \nL 154.297988 104.016865 \nL 154.457794 103.996919 \nL 154.731749 104.118874 \nL 155.005704 103.998139 \nL 155.233999 104.07914 \nL 155.370977 104.07933 \nL 155.462295 104.039302 \nL 155.69059 103.959583 \nL 155.804738 103.939869 \nL 155.987375 103.90043 \nL 156.170011 103.940888 \nL 156.306988 103.941267 \nL 156.398307 103.901733 \nL 156.512454 103.921963 \nL 156.786409 104.041657 \nL 156.969046 104.002418 \nL 157.311489 104.180572 \nL 157.516955 104.121629 \nL 157.722421 104.180729 \nL 157.836569 104.200391 \nL 158.087694 104.298263 \nL 158.27033 104.25906 \nL 158.475796 104.317457 \nL 158.612774 104.31733 \nL 158.704092 104.278344 \nL 158.841069 104.27827 \nL 159.000876 104.297574 \nL 159.206342 104.239357 \nL 159.32049 104.22 \nL 159.525956 104.162108 \nL 159.640104 104.142899 \nL 159.777081 104.143004 \nL 160.028206 104.239204 \nL 160.210843 104.200833 \nL 160.302161 104.16254 \nL 160.598945 104.029008 \nL 160.713093 104.010135 \nL 160.827241 104.029419 \nL 160.964218 104.029671 \nL 161.124025 104.010945 \nL 161.283832 104.030239 \nL 161.489298 103.973788 \nL 161.649105 103.993071 \nL 161.831741 103.955703 \nL 161.968718 103.95604 \nL 162.242673 103.843884 \nL 162.40248 103.86322 \nL 162.539457 103.863672 \nL 162.744923 103.920512 \nL 162.881901 103.92089 \nL 162.973219 103.883786 \nL 163.155855 103.847059 \nL 163.247173 103.810112 \nL 163.361321 103.829153 \nL 163.498299 103.829648 \nL 163.703765 103.774732 \nL 163.863571 103.79391 \nL 163.95489 103.831288 \nL 164.365822 104.054032 \nL 164.479969 104.072632 \nL 164.708265 104.146474 \nL 165.050708 103.981768 \nL 165.233345 104.018757 \nL 165.621447 103.818923 \nL 165.735595 103.801122 \nL 165.872572 103.801648 \nL 165.963891 103.765637 \nL 166.123697 103.748152 \nL 166.260675 103.74873 \nL 166.48897 103.677338 \nL 166.694436 103.732506 \nL 166.854243 103.715179 \nL 167.059709 103.770095 \nL 167.493471 103.538781 \nL 167.676107 103.575686 \nL 167.835914 103.558727 \nL 168.087039 103.64936 \nL 168.246846 103.632358 \nL 168.406653 103.650968 \nL 168.54363 103.651652 \nL 168.771926 103.723695 \nL 168.908903 103.724295 \nL 169.09154 103.760443 \nL 169.205687 103.778559 \nL 169.342665 103.779085 \nL 169.456813 103.797148 \nL 169.685108 103.86833 \nL 169.867745 103.833769 \nL 170.027551 103.851843 \nL 170.164529 103.852285 \nL 170.369995 103.870411 \nL 170.506972 103.870832 \nL 170.712438 103.888874 \nL 170.940734 103.854745 \nL 171.214688 103.925012 \nL 171.534302 103.822004 \nL 171.739768 103.839973 \nL 171.945234 103.823402 \nL 172.333337 103.979392 \nL 172.65295 103.877214 \nL 172.812757 103.86056 \nL 173.063882 103.810081 \nL 173.246519 103.810722 \nL 173.383496 103.845261 \nL 173.566133 103.84584 \nL 173.70311 103.880242 \nL 173.931405 103.914813 \nL 174.182531 103.864692 \nL 174.365167 103.865238 \nL 174.547803 103.865785 \nL 174.913076 104.001388 \nL 175.141372 103.968236 \nL 175.460986 104.069341 \nL 175.712111 104.019546 \nL 175.849088 103.986405 \nL 176.123043 103.920344 \nL 176.305679 103.920796 \nL 176.556804 103.871642 \nL 176.716611 103.855534 \nL 176.853589 103.889043 \nL 177.013395 103.872956 \nL 177.31018 103.791365 \nL 177.492816 103.792007 \nL 177.721112 103.759938 \nL 177.926578 103.777118 \nL 178.086385 103.794067 \nL 178.497317 103.958763 \nL 178.725612 103.926652 \nL 178.999567 103.992345 \nL 179.136544 104.025087 \nL 179.36484 104.05787 \nL 179.501817 104.090433 \nL 179.684454 104.090622 \nL 179.88992 104.074693 \nL 180.072556 104.074903 \nL 180.300852 104.042992 \nL 180.597636 104.123679 \nL 180.89442 104.043823 \nL 181.145545 104.092126 \nL 181.351011 104.076375 \nL 181.487988 104.044654 \nL 181.94458 103.854682 \nL 182.150046 103.871137 \nL 182.492489 103.761368 \nL 182.697955 103.777896 \nL 182.94908 103.731486 \nL 183.131716 103.73218 \nL 183.314353 103.732885 \nL 183.45133 103.702004 \nL 183.702455 103.656026 \nL 183.95358 103.704023 \nL 184.273194 103.611729 \nL 184.410172 103.581206 \nL 184.615638 103.566665 \nL 184.843933 103.59887 \nL 185.049399 103.58435 \nL 185.186376 103.554048 \nL 185.391842 103.539633 \nL 185.711456 103.633851 \nL 186.03107 103.542955 \nL 186.213706 103.543902 \nL 186.350684 103.575308 \nL 186.55615 103.591647 \nL 186.807275 103.546951 \nL 187.012741 103.563269 \nL 187.355184 103.458347 \nL 187.58348 103.490069 \nL 187.788946 103.476022 \nL 187.948753 103.461743 \nL 188.199878 103.417773 \nL 188.496662 103.495073 \nL 188.679298 103.496062 \nL 188.930424 103.542577 \nL 189.227208 103.468977 \nL 189.478333 103.515355 \nL 189.797947 103.427288 \nL 190.231708 103.593834 \nL 190.345856 103.639056 \nL 190.551322 103.654806 \nL 190.962254 103.508227 \nL 191.14489 103.509183 \nL 191.327527 103.51014 \nL 191.578652 103.55573 \nL 191.829777 103.512748 \nL 192.058073 103.543344 \nL 192.17222 103.588009 \nL 192.332027 103.574056 \nL 192.514664 103.574919 \nL 192.6973 103.575781 \nL 192.902766 103.562123 \nL 193.153891 103.607092 \nL 193.382187 103.578967 \nL 193.564823 103.579818 \nL 193.770289 103.566234 \nL 193.930096 103.552481 \nL 194.135562 103.53897 \nL 194.432346 103.612717 \nL 194.592153 103.627858 \nL 194.888938 103.701174 \nL 195.048744 103.716167 \nL 195.25421 103.731276 \nL 195.619483 103.617859 \nL 196.030415 103.762556 \nL 196.3272 103.692195 \nL 196.441347 103.649864 \nL 196.623984 103.6506 \nL 196.82945 103.665636 \nL 197.103404 103.609963 \nL 197.286041 103.610751 \nL 197.537166 103.569388 \nL 197.788291 103.612896 \nL 197.948098 103.627679 \nL 198.107905 103.614252 \nL 198.290541 103.61502 \nL 198.518837 103.644081 \nL 198.724303 103.630876 \nL 198.952598 103.659821 \nL 199.112405 103.674436 \nL 199.340701 103.703235 \nL 199.660315 103.620761 \nL 199.865781 103.635523 \nL 200.162565 103.567285 \nL 200.368031 103.582079 \nL 200.619156 103.541641 \nL 200.824622 103.556424 \nL 201.030088 103.543555 \nL 201.281213 103.586064 \nL 201.44102 103.600521 \nL 201.600827 103.587441 \nL 201.783463 103.58823 \nL 201.988929 103.602834 \nL 202.377032 103.481352 \nL 202.742305 103.592341 \nL 203.221725 103.417562 \nL 203.564169 103.514399 \nL 203.906612 103.421263 \nL 204.066419 103.408594 \nL 204.317544 103.36946 \nL 204.454521 103.343258 \nL 204.614328 103.357673 \nL 204.842624 103.385893 \nL 205.02526 103.386913 \nL 205.207897 103.387923 \nL 205.413363 103.375663 \nL 205.755806 103.471185 \nL 206.029761 103.41915 \nL 206.235227 103.433575 \nL 206.349375 103.474118 \nL 206.57767 103.501845 \nL 206.920113 103.410581 \nL 207.171239 103.45166 \nL 207.422364 103.413251 \nL 207.582171 103.400887 \nL 207.810466 103.375726 \nL 208.289887 103.549327 \nL 208.541012 103.511034 \nL 208.974773 103.657046 \nL 209.203069 103.631738 \nL 209.522683 103.711226 \nL 209.705319 103.711835 \nL 209.887956 103.712435 \nL 210.002103 103.751821 \nL 210.344547 103.843684 \nL 210.618501 103.792532 \nL 210.846797 103.819028 \nL 211.075093 103.793783 \nL 211.280559 103.807252 \nL 211.531684 103.769275 \nL 211.828468 103.8344 \nL 211.942616 103.873208 \nL 212.193741 103.912237 \nL 212.399207 103.89983 \nL 212.581843 103.900198 \nL 212.74165 103.91331 \nL 213.221071 104.079855 \nL 213.563514 103.991178 \nL 213.883128 104.042383 \nL 214.111423 104.042635 \nL 214.499526 104.131533 \nL 214.978947 103.993197 \nL 215.230072 104.00614 \nL 215.412708 104.031511 \nL 215.618174 104.019199 \nL 215.869299 104.006992 \nL 216.257402 104.094996 \nL 216.462868 104.107645 \nL 216.759652 104.145233 \nL 217.010777 104.13291 \nL 217.35322 104.195165 \nL 217.581516 104.195207 \nL 217.8783 104.232375 \nL 218.220743 104.170604 \nL 218.471869 104.183011 \nL 218.677335 104.195365 \nL 218.90563 104.195407 \nL 219.088267 104.22 \nL 219.293733 104.20773 \nL 219.45354 104.244514 \nL 219.613346 104.207751 \nL 219.841642 104.207772 \nL 220.092767 104.22 \nL 220.389551 104.183442 \nL 220.731995 104.244325 \nL 221.005949 104.22 \nL 221.257074 104.232123 \nL 221.576688 104.183694 \nL 221.850643 104.207919 \nL 222.124598 104.18382 \nL 222.352893 104.183862 \nL 222.626848 104.159879 \nL 222.946462 104.208003 \nL 223.083439 104.255975 \nL 223.334564 104.267898 \nL 223.471541 104.315711 \nL 223.791155 104.363299 \nL 224.156428 104.291492 \nL 224.361894 104.279505 \nL 224.727167 104.208129 \nL 225.023951 104.24371 \nL 225.297906 104.22 \nL 225.59469 104.255444 \nL 225.868645 104.231797 \nL 226.09694 104.231781 \nL 226.507872 104.137736 \nL 226.713338 104.126097 \nL 226.895975 104.149649 \nL 227.1471 104.161457 \nL 227.329736 104.184914 \nL 227.64935 104.231676 \nL 227.831986 104.254986 \nL 228.083112 104.266578 \nL 228.357066 104.243252 \nL 228.67668 104.289631 \nL 228.950635 104.266347 \nL 229.20176 104.277849 \nL 229.567033 104.208455 \nL 229.977965 104.300634 \nL 230.20626 104.300529 \nL 230.411726 104.288942 \nL 230.73134 104.242937 \nL 230.959636 104.242911 \nL 231.302079 104.185702 \nL 231.667352 104.254224 \nL 232.055454 104.174463 \nL 232.329409 104.197268 \nL 232.557704 104.1973 \nL 232.786 104.197331 \nL 233.082784 104.163412 \nL 233.356739 104.186102 \nL 233.607864 104.174862 \nL 233.950307 104.231261 \nL 234.201432 104.22 \nL 234.452558 104.231229 \nL 234.680853 104.231219 \nL 234.909149 104.231203 \nL 235.114615 104.24238 \nL 235.525547 104.331646 \nL 235.753842 104.331504 \nL 235.913649 104.297984 \nL 236.141945 104.297884 \nL 236.415899 104.319985 \nL 236.575706 104.3532 \nL 236.804002 104.353032 \nL 237.123616 104.30853 \nL 237.351911 104.30842 \nL 237.557377 104.31936 \nL 237.831332 104.341261 \nL 238.150946 104.297033 \nL 238.379241 104.296933 \nL 238.630366 104.285856 \nL 238.97281 104.340509 \nL 239.497889 104.198151 \nL 239.794674 104.230909 \nL 240.091458 104.198225 \nL 240.319753 104.198246 \nL 240.548049 104.198278 \nL 240.707856 104.165736 \nL 240.936151 104.165799 \nL 241.164447 104.165873 \nL 241.52972 104.101147 \nL 241.758015 104.101294 \nL 242.077629 104.058406 \nL 242.420073 104.11246 \nL 242.694027 104.091148 \nL 242.899493 104.08056 \nL 243.104959 104.091432 \nL 243.378914 104.113017 \nL 243.675698 104.081138 \nL 243.926823 104.091989 \nL 244.155119 104.092147 \nL 244.451903 104.124257 \nL 244.703028 104.113764 \nL 244.885665 104.09263 \nL 245.068301 104.113964 \nL 245.456403 104.188257 \nL 245.935824 104.072222 \nL 246.301097 104.135718 \nL 246.597881 104.104291 \nL 246.871836 104.125466 \nL 247.008813 104.167523 \nL 247.442575 104.261889 \nL 247.716529 104.240913 \nL 248.058973 104.293074 \nL 248.332927 104.272119 \nL 248.515564 104.251243 \nL 248.6982 104.272025 \nL 248.926496 104.271961 \nL 249.063473 104.313467 \nL 249.291769 104.313356 \nL 249.679871 104.240703 \nL 249.862508 104.22 \nL 250.090803 104.22 \nL 250.456076 104.281866 \nL 250.661542 104.292102 \nL 251.003985 104.343385 \nL 251.369258 104.281577 \nL 251.529065 104.250765 \nL 251.848679 104.209759 \nL 252.076975 104.20977 \nL 252.373759 104.179152 \nL 252.784691 104.260759 \nL 253.195623 104.179331 \nL 253.720703 104.311274 \nL 254.085975 104.25037 \nL 254.314271 104.230109 \nL 254.679544 104.189719 \nL 254.976328 104.199844 \nL 255.227453 104.209938 \nL 255.638385 104.270221 \nL 256.003658 104.230025 \nL 256.231954 104.20999 \nL 256.551567 104.190003 \nL 257.008159 104.26988 \nL 257.213625 104.29973 \nL 257.556068 104.329443 \nL 257.921341 104.28952 \nL 258.240955 104.30924 \nL 258.606227 104.269491 \nL 259.039989 104.338522 \nL 259.473751 104.26928 \nL 260.090149 104.416522 \nL 260.295615 104.445778 \nL 260.569569 104.445473 \nL 260.980501 104.386325 \nL 261.140308 104.337313 \nL 261.528411 104.288306 \nL 261.779536 104.278475 \nL 262.07632 104.26866 \nL 262.6014 104.375317 \nL 262.898184 104.365402 \nL 263.263457 104.403852 \nL 263.446093 104.442361 \nL 263.742878 104.451697 \nL 264.13098 104.40309 \nL 264.473423 104.431647 \nL 264.907185 104.364009 \nL 265.226799 104.382961 \nL 265.500753 104.38275 \nL 265.843197 104.41116 \nL 266.094322 104.420475 \nL 266.505254 104.477252 \nL 266.802038 104.467379 \nL 267.053163 104.45758 \nL 267.349947 104.44776 \nL 267.760879 104.504148 \nL 268.080493 104.484807 \nL 268.377277 104.493886 \nL 268.651232 104.493534 \nL 268.925187 104.493181 \nL 269.176312 104.502271 \nL 269.495926 104.520639 \nL 269.815539 104.50143 \nL 270.066664 104.491731 \nL 270.386278 104.472616 \nL 270.637403 104.462974 \nL 271.025506 104.415896 \nL 271.29946 104.415649 \nL 271.596245 104.406076 \nL 271.915858 104.424381 \nL 272.144154 104.442729 \nL 272.395279 104.433198 \nL 272.646404 104.442214 \nL 272.920359 104.441935 \nL 273.285632 104.404636 \nL 273.582416 104.413604 \nL 273.8792 104.404136 \nL 274.107496 104.385547 \nL 274.472769 104.348542 \nL 274.860871 104.394148 \nL 275.111996 104.403101 \nL 275.363121 104.393748 \nL 275.682735 104.375233 \nL 275.911031 104.356827 \nL 276.367622 104.283722 \nL 276.801383 104.347196 \nL 277.235145 104.283475 \nL 277.5091 104.283396 \nL 277.737395 104.301422 \nL 278.102668 104.337418 \nL 278.376623 104.337276 \nL 278.878873 104.427021 \nL 279.107169 104.444795 \nL 279.403953 104.453474 \nL 279.906203 104.363357 \nL 280.271476 104.398905 \nL 280.750897 104.318187 \nL 281.07051 104.335878 \nL 281.367295 104.326825 \nL 281.59559 104.30893 \nL 282.166329 104.193388 \nL 282.577261 104.246564 \nL 282.896875 104.228842 \nL 283.12517 104.211168 \nL 283.467614 104.149439 \nL 283.467614 104.149439 \n\" clip-path=\"url(#pfb46636bbe)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 43.78125 104.22 \nL 294.88125 104.22 \n\" clip-path=\"url(#pfb46636bbe)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #000000; stroke-width: 1.5\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 201.24 \nL 43.78125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 294.88125 201.24 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 201.24 \nL 294.88125 201.24 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 7.2 \nL 294.88125 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 182.759375 44.55625 \nL 287.88125 44.55625 \nQ 289.88125 44.55625 289.88125 42.55625 \nL 289.88125 14.2 \nQ 289.88125 12.2 287.88125 12.2 \nL 182.759375 12.2 \nQ 180.759375 12.2 180.759375 14.2 \nL 180.759375 42.55625 \nQ 180.759375 44.55625 182.759375 44.55625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_16\">\n     <path d=\"M 184.759375 20.298438 \nL 194.759375 20.298438 \nL 204.759375 20.298438 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_15\">\n     <!-- P(coin=heads) -->\n     <g transform=\"translate(212.759375 23.798438) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-50\" d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-3d\" d=\"M 678 2906 \nL 4684 2906 \nL 4684 2381 \nL 678 2381 \nL 678 2906 \nz\nM 678 1631 \nL 4684 1631 \nL 4684 1100 \nL 678 1100 \nL 678 1631 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"453.808594\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"515.332031\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"576.611328\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"640.087891\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"692.1875\"/>\n     </g>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 184.759375 34.976562 \nL 194.759375 34.976562 \nL 204.759375 34.976562 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_16\">\n     <!-- P(coin=tails) -->\n     <g transform=\"translate(212.759375 38.476562) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use xlink:href=\"#DejaVuSans-28\" x=\"60.302734\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"99.316406\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"154.296875\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"215.478516\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"243.261719\"/>\n      <use xlink:href=\"#DejaVuSans-3d\" x=\"306.640625\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"390.429688\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"429.638672\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"490.917969\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"518.701172\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"546.484375\"/>\n      <use xlink:href=\"#DejaVuSans-29\" x=\"598.583984\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pfb46636bbe\">\n   <rect x=\"43.78125\" y=\"7.2\" width=\"251.1\" height=\"194.04\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "counts = Multinomial(1, fair_probs).sample((10000,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "print(cum_counts)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "estimates = estimates.numpy()\n",
        "\n",
        "d2l.set_figsize((4.5, 3.5))\n",
        "d2l.plt.plot(estimates[:, 0], label=(\"P(coin=heads)\"))\n",
        "d2l.plt.plot(estimates[:, 1], label=(\"P(coin=tails)\"))\n",
        "d2l.plt.axhline(y=0.5, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Samples')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec40585d",
      "metadata": {
        "origin_pos": 29,
        "id": "ec40585d"
      },
      "source": [
        "Each solid curve corresponds to one of the two values of the coin\n",
        "and gives our estimated probability that the coin turns up that value\n",
        "after each group of experiments.\n",
        "The dashed black line gives the true underlying probability.\n",
        "As we get more data by conducting more experiments,\n",
        "the curves converge towards the true probability.\n",
        "You might already begin to see the shape\n",
        "of some of the more advanced questions\n",
        "that preoccupy statisticians:\n",
        "How quickly does this convergence happen?\n",
        "If we had already tested many coins\n",
        "manufactured at the same plant,\n",
        "how might we incorporate this information?\n",
        "\n",
        "##  A More Formal Treatment\n",
        "\n",
        "We have already gotten pretty far: posing\n",
        "a probabilistic model,\n",
        "generating synthetic data,\n",
        "running a statistical estimator,\n",
        "empirically assessing convergence,\n",
        "and reporting error metrics (checking the deviation).\n",
        "However, to go much further,\n",
        "we will need to be more precise.\n",
        "\n",
        "\n",
        "When dealing with randomness,\n",
        "we denote the set of possible outcomes $\\mathcal{S}$\n",
        "and call it the *sample space* or *outcome space*.\n",
        "Here, each element is a distinct possible *outcome*.\n",
        "In the case of rolling a single coin,\n",
        "$\\mathcal{S} = \\{\\textrm{heads}, \\textrm{tails}\\}$.\n",
        "For a single die, $\\mathcal{S} = \\{1, 2, 3, 4, 5, 6\\}$.\n",
        "When flipping two coins, possible outcomes are\n",
        "$\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails}), (\\textrm{tails}, \\textrm{heads}),  (\\textrm{tails}, \\textrm{tails})\\}$.\n",
        "*Events* are subsets of the sample space.\n",
        "For instance, the event \"the first coin toss comes up heads\"\n",
        "corresponds to the set $\\{(\\textrm{heads}, \\textrm{heads}), (\\textrm{heads}, \\textrm{tails})\\}$.\n",
        "Whenever the outcome $z$ of a random experiment satisfies\n",
        "$z \\in \\mathcal{A}$, then event $\\mathcal{A}$ has occurred.\n",
        "For a single roll of a die, we could define the events\n",
        "\"seeing a $5$\" ($\\mathcal{A} = \\{5\\}$)\n",
        "and \"seeing an odd number\"  ($\\mathcal{B} = \\{1, 3, 5\\}$).\n",
        "In this case, if the die came up $5$,\n",
        "we would say that both $\\mathcal{A}$ and $\\mathcal{B}$ occurred.\n",
        "On the other hand, if $z = 3$,\n",
        "then $\\mathcal{A}$ did not occur\n",
        "but $\\mathcal{B}$ did.\n",
        "\n",
        "\n",
        "A *probability* function maps events\n",
        "onto real values ${P: \\mathcal{A} \\subseteq \\mathcal{S} \\rightarrow [0,1]}$.\n",
        "The probability, denoted $P(\\mathcal{A})$, of an event $\\mathcal{A}$\n",
        "in the given sample space $\\mathcal{S}$,\n",
        "has the following properties:\n",
        "\n",
        "* The probability of any event $\\mathcal{A}$ is a nonnegative real number, i.e., $P(\\mathcal{A}) \\geq 0$;\n",
        "* The probability of the entire sample space is $1$, i.e., $P(\\mathcal{S}) = 1$;\n",
        "* For any countable sequence of events $\\mathcal{A}_1, \\mathcal{A}_2, \\ldots$ that are *mutually exclusive* (i.e., $\\mathcal{A}_i \\cap \\mathcal{A}_j = \\emptyset$ for all $i \\neq j$), the probability that any of them happens is equal to the sum of their individual probabilities, i.e., $P(\\bigcup_{i=1}^{\\infty} \\mathcal{A}_i) = \\sum_{i=1}^{\\infty} P(\\mathcal{A}_i)$.\n",
        "\n",
        "These axioms of probability theory,\n",
        "proposed by :citet:`Kolmogorov.1933`,\n",
        "can be applied to rapidly derive a number of important consequences.\n",
        "For instance, it follows immediately\n",
        "that the probability of any event $\\mathcal{A}$\n",
        "*or* its complement $\\mathcal{A}'$ occurring is 1\n",
        "(because $\\mathcal{A} \\cup \\mathcal{A}' = \\mathcal{S}$).\n",
        "We can also prove that $P(\\emptyset) = 0$\n",
        "because $1 = P(\\mathcal{S} \\cup \\mathcal{S}') = P(\\mathcal{S} \\cup \\emptyset) = P(\\mathcal{S}) + P(\\emptyset) = 1 + P(\\emptyset)$.\n",
        "Consequently, the probability of any event $\\mathcal{A}$\n",
        "*and* its complement $\\mathcal{A}'$ occurring simultaneously\n",
        "is $P(\\mathcal{A} \\cap \\mathcal{A}') = 0$.\n",
        "Informally, this tells us that impossible events\n",
        "have zero probability of occurring.\n",
        "\n",
        "\n",
        "\n",
        "## Random Variables\n",
        "\n",
        "When we spoke about events like the roll of a die\n",
        "coming up odds or the first coin toss coming up heads,\n",
        "we were invoking the idea of a *random variable*.\n",
        "Formally, random variables are mappings\n",
        "from an underlying sample space\n",
        "to a set of (possibly many) values.\n",
        "You might wonder how a random variable\n",
        "is different from the sample space,\n",
        "since both are collections of outcomes.\n",
        "Importantly, random variables can be much coarser\n",
        "than the raw sample space.\n",
        "We can define a binary random variable like \"greater than 0.5\"\n",
        "even when the underlying sample space is infinite,\n",
        "e.g., points on the line segment between $0$ and $1$.\n",
        "Additionally, multiple random variables\n",
        "can share the same underlying sample space.\n",
        "For example \"whether my home alarm goes off\"\n",
        "and \"whether my house was burgled\"\n",
        "are both binary random variables\n",
        "that share an underlying sample space.\n",
        "Consequently, knowing the value taken by one random variable\n",
        "can tell us something about the likely value of another random variable.\n",
        "Knowing that the alarm went off,\n",
        "we might suspect that the house was likely burgled.\n",
        "\n",
        "\n",
        "Every value taken by a random variable corresponds\n",
        "to a subset of the underlying sample space.\n",
        "Thus the occurrence where the random variable $X$\n",
        "takes value $v$, denoted by $X=v$, is an *event*\n",
        "and $P(X=v)$ denotes its probability.\n",
        "Sometimes this notation can get clunky,\n",
        "and we can abuse notation when the context is clear.\n",
        "For example, we might use $P(X)$ to refer broadly\n",
        "to the *distribution* of $X$, i.e.,\n",
        "the function that tells us the probability\n",
        "that $X$ takes any given value.\n",
        "Other times we write expressions\n",
        "like $P(X,Y) = P(X) P(Y)$,\n",
        "as a shorthand to express a statement\n",
        "that is true for all of the values\n",
        "that the random variables $X$ and $Y$ can take, i.e.,\n",
        "for all $i,j$ it holds that $P(X=i \\textrm{ and } Y=j) = P(X=i)P(Y=j)$.\n",
        "Other times, we abuse notation by writing\n",
        "$P(v)$ when the random variable is clear from the context.\n",
        "Since an event in probability theory is a set of outcomes from the sample space,\n",
        "we can specify a range of values for a random variable to take.\n",
        "For example, $P(1 \\leq X \\leq 3)$ denotes the probability of the event $\\{1 \\leq X \\leq 3\\}$.\n",
        "\n",
        "\n",
        "Note that there is a subtle difference\n",
        "between *discrete* random variables,\n",
        "like flips of a coin or tosses of a die,\n",
        "and *continuous* ones,\n",
        "like the weight and the height of a person\n",
        "sampled at random from the population.\n",
        "In this case we seldom really care about\n",
        "someone's exact height.\n",
        "Moreover, if we took precise enough measurements,\n",
        "we would find that no two people on the planet\n",
        "have the exact same height.\n",
        "In fact, with fine enough measurements,\n",
        "you would never have the same height\n",
        "when you wake up and when you go to sleep.\n",
        "There is little point in asking about\n",
        "the exact probability that someone\n",
        "is 1.801392782910287192 meters tall.\n",
        "Instead, we typically care more about being able to say\n",
        "whether someone's height falls into a given interval,\n",
        "say between 1.79 and 1.81 meters.\n",
        "In these cases we work with probability *densities*.\n",
        "The height of exactly 1.80 meters\n",
        "has no probability, but nonzero density.\n",
        "To work out the probability assigned to an interval,\n",
        "we must take an *integral* of the density\n",
        "over that interval.\n",
        "\n",
        "## Multiple Random Variables\n",
        "\n",
        "You might have noticed that we could not even\n",
        "make it through the previous section without\n",
        "making statements involving interactions\n",
        "among multiple random variables\n",
        "(recall $P(X,Y) = P(X) P(Y)$).\n",
        "Most of machine learning\n",
        "is concerned with such relationships.\n",
        "Here, the sample space would be\n",
        "the population of interest,\n",
        "say customers who transact with a business,\n",
        "photographs on the Internet,\n",
        "or proteins known to biologists.\n",
        "Each random variable would represent\n",
        "the (unknown) value of a different attribute.\n",
        "Whenever we sample an individual from the population,\n",
        "we observe a realization of each of the random variables.\n",
        "Because the values taken by random variables\n",
        "correspond to subsets of the sample space\n",
        "that could be overlapping, partially overlapping,\n",
        "or entirely disjoint,\n",
        "knowing the value taken by one random variable\n",
        "can cause us to update our beliefs\n",
        "about which values of another random variable are likely.\n",
        "If a patient walks into a hospital\n",
        "and we observe that they\n",
        "are having trouble breathing\n",
        "and have lost their sense of smell,\n",
        "then we believe that they are more likely\n",
        "to have COVID-19 than we might\n",
        "if they had no trouble breathing\n",
        "and a perfectly ordinary sense of smell.\n",
        "\n",
        "\n",
        "When working with multiple random variables,\n",
        "we can construct events corresponding\n",
        "to every combination of values\n",
        "that the variables can jointly take.\n",
        "The probability function that assigns\n",
        "probabilities to each of these combinations\n",
        "(e.g. $A=a$ and $B=b$)\n",
        "is called the *joint probability* function\n",
        "and simply returns the probability assigned\n",
        "to the intersection of the corresponding subsets\n",
        "of the sample space.\n",
        "The *joint probability* assigned to the event\n",
        "where random variables $A$ and $B$\n",
        "take values $a$ and $b$, respectively,\n",
        "is denoted $P(A = a, B = b)$,\n",
        "where the comma indicates \"and\".\n",
        "Note that for any values $a$ and $b$,\n",
        "it follows that\n",
        "\n",
        "$$P(A=a, B=b) \\leq P(A=a) \\textrm{ and } P(A=a, B=b) \\leq P(B = b),$$\n",
        "\n",
        "since for $A=a$ and $B=b$ to happen,\n",
        "$A=a$ has to happen *and* $B=b$ also has to happen.\n",
        "Interestingly, the joint probability\n",
        "tells us all that we can know about these\n",
        "random variables in a probabilistic sense,\n",
        "and can be used to derive many other\n",
        "useful quantities, including recovering the\n",
        "individual distributions $P(A)$ and $P(B)$.\n",
        "To recover $P(A=a)$ we simply sum up\n",
        "$P(A=a, B=v)$ over all values $v$\n",
        "that the random variable $B$ can take:\n",
        "$P(A=a) = \\sum_v P(A=a, B=v)$.\n",
        "\n",
        "\n",
        "The ratio $\\frac{P(A=a, B=b)}{P(A=a)} \\leq 1$\n",
        "turns out to be extremely important.\n",
        "It is called the *conditional probability*,\n",
        "and is denoted via the \"$\\mid$\" symbol:\n",
        "\n",
        "$$P(B=b \\mid A=a) = P(A=a,B=b)/P(A=a).$$\n",
        "\n",
        "It tells us the new probability\n",
        "associated with the event $B=b$,\n",
        "once we condition on the fact $A=a$ took place.\n",
        "We can think of this conditional probability\n",
        "as restricting attention only to the subset\n",
        "of the sample space associated with $A=a$\n",
        "and then renormalizing so that\n",
        "all probabilities sum to 1.\n",
        "Conditional probabilities\n",
        "are in fact just ordinary probabilities\n",
        "and thus respect all of the axioms,\n",
        "as long as we condition all terms\n",
        "on the same event and thus\n",
        "restrict attention to the same sample space.\n",
        "For instance, for disjoint events\n",
        "$\\mathcal{B}$ and $\\mathcal{B}'$, we have that\n",
        "$P(\\mathcal{B} \\cup \\mathcal{B}' \\mid A = a) = P(\\mathcal{B} \\mid A = a) + P(\\mathcal{B}' \\mid A = a)$.\n",
        "\n",
        "\n",
        "Using the definition of conditional probabilities,\n",
        "we can derive the famous result called *Bayes' theorem*.\n",
        "By construction, we have that $P(A, B) = P(B\\mid A) P(A)$\n",
        "and $P(A, B) = P(A\\mid B) P(B)$.\n",
        "Combining both equations yields\n",
        "$P(B\\mid A) P(A) = P(A\\mid B) P(B)$ and hence\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}.$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This simple equation has profound implications because\n",
        "it allows us to reverse the order of conditioning.\n",
        "If we know how to estimate $P(B\\mid A)$, $P(A)$, and $P(B)$,\n",
        "then we can estimate $P(A\\mid B)$.\n",
        "We often find it easier to estimate one term directly\n",
        "but not the other and Bayes' theorem can come to the rescue here.\n",
        "For instance, if we know the prevalence of symptoms for a given disease,\n",
        "and the overall prevalences of the disease and symptoms, respectively,\n",
        "we can determine how likely someone is\n",
        "to have the disease based on their symptoms.\n",
        "In some cases we might not have direct access to $P(B)$,\n",
        "such as the prevalence of symptoms.\n",
        "In this case a simplified version of Bayes' theorem comes in handy:\n",
        "\n",
        "$$P(A \\mid B) \\propto P(B \\mid A) P(A).$$\n",
        "\n",
        "Since we know that $P(A \\mid B)$ must be normalized to $1$, i.e., $\\sum_a P(A=a \\mid B) = 1$,\n",
        "we can use it to compute\n",
        "\n",
        "$$P(A \\mid B) = \\frac{P(B \\mid A) P(A)}{\\sum_a P(B \\mid A=a) P(A = a)}.$$\n",
        "\n",
        "In Bayesian statistics, we think of an observer\n",
        "as possessing some (subjective) prior beliefs\n",
        "about the plausibility of the available hypotheses\n",
        "encoded in the *prior* $P(H)$,\n",
        "and a *likelihood function* that says how likely\n",
        "one is to observe any value of the collected evidence\n",
        "for each of the hypotheses in the class $P(E \\mid H)$.\n",
        "Bayes' theorem is then interpreted as telling us\n",
        "how to update the initial *prior* $P(H)$\n",
        "in light of the available evidence $E$\n",
        "to produce *posterior* beliefs\n",
        "$P(H \\mid E) = \\frac{P(E \\mid H) P(H)}{P(E)}$.\n",
        "Informally, this can be stated as\n",
        "\"posterior equals prior times likelihood, divided by the evidence\".\n",
        "Now, because the evidence $P(E)$ is the same for all hypotheses,\n",
        "we can get away with simply normalizing over the hypotheses.\n",
        "\n",
        "Note that $\\sum_a P(A=a \\mid B) = 1$ also allows us to *marginalize* over random variables. That is, we can drop variables from a joint distribution such as $P(A, B)$. After all, we have that\n",
        "\n",
        "$$\\sum_a P(B \\mid A=a) P(A=a) = \\sum_a P(B, A=a) = P(B).$$\n",
        "\n",
        "Independence is another fundamentally important concept\n",
        "that forms the backbone of\n",
        "many important ideas in statistics.\n",
        "In short, two variables are *independent*\n",
        "if conditioning on the value of $A$ does not\n",
        "cause any change to the probability distribution\n",
        "associated with $B$ and vice versa.\n",
        "More formally, independence, denoted $A \\perp B$,\n",
        "requires that $P(A \\mid B) = P(A)$ and, consequently,\n",
        "that $P(A,B) = P(A \\mid B) P(B) = P(A) P(B)$.\n",
        "Independence is often an appropriate assumption.\n",
        "For example, if the random variable $A$\n",
        "represents the outcome from tossing one fair coin\n",
        "and the random variable $B$\n",
        "represents the outcome from tossing another,\n",
        "then knowing whether $A$ came up heads\n",
        "should not influence the probability\n",
        "of $B$ coming up heads.\n",
        "\n",
        "\n",
        "Independence is especially useful when it holds among the successive\n",
        "draws of our data from some underlying distribution\n",
        "(allowing us to make strong statistical conclusions)\n",
        "or when it holds among various variables in our data,\n",
        "allowing us to work with simpler models\n",
        "that encode this independence structure.\n",
        "On the other hand, estimating the dependencies\n",
        "among random variables is often the very aim of learning.\n",
        "We care to estimate the probability of disease given symptoms\n",
        "specifically because we believe\n",
        "that diseases and symptoms are *not* independent.\n",
        "\n",
        "\n",
        "Note that because conditional probabilities are proper probabilities,\n",
        "the concepts of independence and dependence also apply to them.\n",
        "Two random variables $A$ and $B$ are *conditionally independent*\n",
        "given a third variable $C$ if and only if $P(A, B \\mid C) = P(A \\mid C)P(B \\mid C)$.\n",
        "Interestingly, two variables can be independent in general\n",
        "but become dependent when conditioning on a third.\n",
        "This often occurs when the two random variables $A$ and $B$\n",
        "correspond to causes of some third variable $C$.\n",
        "For example, broken bones and lung cancer might be independent\n",
        "in the general population but if we condition on being in the hospital\n",
        "then we might find that broken bones are negatively correlated with lung cancer.\n",
        "That is because the broken bone *explains away* why some person is in the hospital\n",
        "and thus lowers the probability that they are hospitalized because of having lung cancer.\n",
        "\n",
        "\n",
        "And conversely, two dependent random variables\n",
        "can become independent upon conditioning on a third.\n",
        "This often happens when two otherwise unrelated events\n",
        "have a common cause.\n",
        "Shoe size and reading level are highly correlated\n",
        "among elementary school students,\n",
        "but this correlation disappears if we condition on age.\n",
        "\n",
        "\n",
        "\n",
        "## An Example\n",
        ":label:`subsec_probability_hiv_app`\n",
        "\n",
        "Let's put our skills to the test.\n",
        "Assume that a doctor administers an HIV test to a patient.\n",
        "This test is fairly accurate and fails only with 1% probability\n",
        "if the patient is healthy but reported as diseased,\n",
        "i.e., healthy patients test positive in 1% of cases.\n",
        "Moreover, it never fails to detect HIV if the patient actually has it.\n",
        "We use $D_1 \\in \\{0, 1\\}$ to indicate the diagnosis\n",
        "($0$ if negative and $1$ if positive)\n",
        "and $H \\in \\{0, 1\\}$ to denote the HIV status.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_1 = 1 \\mid H)$        |     1 |  0.01 |\n",
        "| $P(D_1 = 0 \\mid H)$        |     0 |  0.99 |\n",
        "\n",
        "Note that the column sums are all 1 (but the row sums do not),\n",
        "since they are conditional probabilities.\n",
        "Let's compute the probability of the patient having HIV\n",
        "if the test comes back positive, i.e., $P(H = 1 \\mid D_1 = 1)$.\n",
        "Intuitively this is going to depend on how common the disease is,\n",
        "since it affects the number of false alarms.\n",
        "Assume that the population is fairly free of the disease, e.g., $P(H=1) = 0.0015$.\n",
        "To apply Bayes' theorem, we need to apply marginalization\n",
        "to determine\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1)\n",
        "=& P(D_1=1, H=0) + P(D_1=1, H=1)  \\\\\n",
        "=& P(D_1=1 \\mid H=0) P(H=0) + P(D_1=1 \\mid H=1) P(H=1) \\\\\n",
        "=& 0.011485.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "This leads us to\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1) = \\frac{P(D_1=1 \\mid H=1) P(H=1)}{P(D_1=1)} = 0.1306.$$\n",
        "\n",
        "In other words, there is only a 13.06% chance\n",
        "that the patient actually has HIV,\n",
        "despite the test being pretty accurate.\n",
        "As we can see, probability can be counterintuitive.\n",
        "What should a patient do upon receiving such terrifying news?\n",
        "Likely, the patient would ask the physician\n",
        "to administer another test to get clarity.\n",
        "The second test has different characteristics\n",
        "and it is not as good as the first one.\n",
        "\n",
        "| Conditional probability | $H=1$ | $H=0$ |\n",
        "|:------------------------|------:|------:|\n",
        "| $P(D_2 = 1 \\mid H)$          |  0.98 |  0.03 |\n",
        "| $P(D_2 = 0 \\mid H)$          |  0.02 |  0.97 |\n",
        "\n",
        "Unfortunately, the second test comes back positive, too.\n",
        "Let's calculate the requisite probabilities to invoke Bayes' theorem\n",
        "by assuming conditional independence:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 0)\n",
        "& = P(D_1 = 1 \\mid H = 0) P(D_2 = 1 \\mid H = 0)\n",
        "=& 0.0003, \\\\\n",
        "P(D_1 = 1, D_2 = 1 \\mid H = 1)\n",
        "& = P(D_1 = 1 \\mid H = 1) P(D_2 = 1 \\mid H = 1)\n",
        "=& 0.98.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Now we can apply marginalization to obtain the probability\n",
        "that both tests come back positive:\n",
        "\n",
        "$$\\begin{aligned}\n",
        "&P(D_1 = 1, D_2 = 1)\\\\\n",
        "&= P(D_1 = 1, D_2 = 1, H = 0) + P(D_1 = 1, D_2 = 1, H = 1)  \\\\\n",
        "&= P(D_1 = 1, D_2 = 1 \\mid H = 0)P(H=0) + P(D_1 = 1, D_2 = 1 \\mid H = 1)P(H=1)\\\\\n",
        "&= 0.00176955.\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "Finally, the probability of the patient having HIV given that both tests are positive is\n",
        "\n",
        "$$P(H = 1 \\mid D_1 = 1, D_2 = 1)\n",
        "= \\frac{P(D_1 = 1, D_2 = 1 \\mid H=1) P(H=1)}{P(D_1 = 1, D_2 = 1)}\n",
        "= 0.8307.$$\n",
        "\n",
        "That is, the second test allowed us to gain much higher confidence that not all is well.\n",
        "Despite the second test being considerably less accurate than the first one,\n",
        "it still significantly improved our estimate.\n",
        "The assumption of both tests being conditionally independent of each other\n",
        "was crucial for our ability to generate a more accurate estimate.\n",
        "Take the extreme case where we run the same test twice.\n",
        "In this situation we would expect the same outcome both times,\n",
        "hence no additional insight is gained from running the same test again.\n",
        "The astute reader might have noticed that the diagnosis behaved\n",
        "like a classifier hiding in plain sight\n",
        "where our ability to decide whether a patient is healthy\n",
        "increases as we obtain more features (test outcomes).\n",
        "\n",
        "\n",
        "## Expectations\n",
        "\n",
        "Often, making decisions requires not just looking\n",
        "at the probabilities assigned to individual events\n",
        "but composing them together into useful aggregates\n",
        "that can provide us with guidance.\n",
        "For example, when random variables take continuous scalar values,\n",
        "we often care about knowing what value to expect *on average*.\n",
        "This quantity is formally called an *expectation*.\n",
        "If we are making investments,\n",
        "the first quantity of interest\n",
        "might be the return we can expect,\n",
        "averaging over all the possible outcomes\n",
        "(and weighting by the appropriate probabilities).\n",
        "For instance, say that with 50% probability,\n",
        "an investment might fail altogether,\n",
        "with 40% probability it might provide a 2$\\times$ return,\n",
        "and with 10% probability it might provide a 10$\\times$ return 10$\\times$.\n",
        "To calculate the expected return,\n",
        "we sum over all returns, multiplying each\n",
        "by the probability that they will occur.\n",
        "This yields the expectation\n",
        "$0.5 \\cdot 0 + 0.4 \\cdot 2 + 0.1 \\cdot 10 = 1.8$.\n",
        "Hence the expected return is 1.8$\\times$.\n",
        "\n",
        "\n",
        "In general, the *expectation* (or average)\n",
        "of the random variable $X$ is defined as\n",
        "\n",
        "$$E[X] = E_{x \\sim P}[x] = \\sum_{x} x P(X = x).$$\n",
        "\n",
        "Likewise, for densities we obtain $E[X] = \\int x \\;dp(x)$.\n",
        "Sometimes we are interested in the expected value\n",
        "of some function of $x$.\n",
        "We can calculate these expectations as\n",
        "\n",
        "$$E_{x \\sim P}[f(x)] = \\sum_x f(x) P(x) \\textrm{ and } E_{x \\sim P}[f(x)] = \\int f(x) p(x) \\;dx$$\n",
        "\n",
        "for discrete probabilities and densities, respectively.\n",
        "Returning to the investment example from above,\n",
        "$f$ might be the *utility* (happiness)\n",
        "associated with the return.\n",
        "Behavior economists have long noted\n",
        "that people associate greater disutility\n",
        "with losing money than the utility gained\n",
        "from earning one dollar relative to their baseline.\n",
        "Moreover, the value of money tends to be sub-linear.\n",
        "Possessing 100k dollars versus zero dollars\n",
        "can make the difference between paying the rent,\n",
        "eating well, and enjoying quality healthcare\n",
        "versus suffering through homelessness.\n",
        "On the other hand, the gains due to possessing\n",
        "200k versus 100k are less dramatic.\n",
        "Reasoning like this motivates the cliché\n",
        "that \"the utility of money is logarithmic\".\n",
        "\n",
        "\n",
        "If  the utility associated with a total loss were $-1$,\n",
        "and the utilities associated with returns of $1$, $2$, and $10$\n",
        "were $1$, $2$ and $4$, respectively,\n",
        "then the expected happiness of investing\n",
        "would be $0.5 \\cdot (-1) + 0.4 \\cdot 2 + 0.1 \\cdot 4 = 0.7$\n",
        "(an expected loss of utility of 30%).\n",
        "If indeed this were your utility function,\n",
        "you might be best off keeping the money in the bank.\n",
        "\n",
        "For financial decisions,\n",
        "we might also want to measure\n",
        "how *risky* an investment is.\n",
        "Here, we care not just about the expected value\n",
        "but how much the actual values tend to *vary*\n",
        "relative to this value.\n",
        "Note that we cannot just take\n",
        "the expectation of the difference\n",
        "between the actual and expected values.\n",
        "This is because the expectation of a difference\n",
        "is the difference of the expectations,\n",
        "i.e., $E[X - E[X]] = E[X] - E[E[X]] = 0$.\n",
        "However, we can look at the expectation\n",
        "of any non-negative function of this difference.\n",
        "The *variance* of a random variable is calculated by looking\n",
        "at the expected value of the *squared* differences:\n",
        "\n",
        "$$\\textrm{Var}[X] = E\\left[(X - E[X])^2\\right] = E[X^2] - E[X]^2.$$\n",
        "\n",
        "Here the equality follows by expanding\n",
        "$(X - E[X])^2 = X^2 - 2 X E[X] + E[X]^2$\n",
        "and taking expectations for each term.\n",
        "The square root of the variance is another\n",
        "useful quantity called the *standard deviation*.\n",
        "While this and the variance\n",
        "convey the same information (either can be calculated from the other),\n",
        "the standard deviation has the nice property\n",
        "that it is expressed in the same units\n",
        "as the original quantity represented\n",
        "by the random variable.\n",
        "\n",
        "Lastly, the variance of a function\n",
        "of a random variable\n",
        "is defined analogously as\n",
        "\n",
        "$$\\textrm{Var}_{x \\sim P}[f(x)] = E_{x \\sim P}[f^2(x)] - E_{x \\sim P}[f(x)]^2.$$\n",
        "\n",
        "Returning to our investment example,\n",
        "we can now compute the variance of the investment.\n",
        "It is given by $0.5 \\cdot 0 + 0.4 \\cdot 2^2 + 0.1 \\cdot 10^2 - 1.8^2 = 8.36$.\n",
        "For all intents and purposes this is a risky investment.\n",
        "Note that by mathematical convention mean and variance\n",
        "are often referenced as $\\mu$ and $\\sigma^2$.\n",
        "This is particularly the case whenever we use it\n",
        "to parametrize a Gaussian distribution.\n",
        "\n",
        "In the same way as we introduced expectations\n",
        "and variance for *scalar* random variables,\n",
        "we can do so for vector-valued ones.\n",
        "Expectations are easy, since we can apply them elementwise.\n",
        "For instance, $\\boldsymbol{\\mu} \\stackrel{\\textrm{def}}{=} E_{\\mathbf{x} \\sim P}[\\mathbf{x}]$\n",
        "has coordinates $\\mu_i = E_{\\mathbf{x} \\sim P}[x_i]$.\n",
        "*Covariances* are more complicated.\n",
        "We define them by taking expectations of the *outer product*\n",
        "of the difference between random variables and their mean:\n",
        "\n",
        "$$\\boldsymbol{\\Sigma} \\stackrel{\\textrm{def}}{=} \\textrm{Cov}_{\\mathbf{x} \\sim P}[\\mathbf{x}] = E_{\\mathbf{x} \\sim P}\\left[(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top\\right].$$\n",
        "\n",
        "This matrix $\\boldsymbol{\\Sigma}$ is referred to as the covariance matrix.\n",
        "An easy way to see its effect is to consider some vector $\\mathbf{v}$\n",
        "of the same size as $\\mathbf{x}$.\n",
        "It follows that\n",
        "\n",
        "$$\\mathbf{v}^\\top \\boldsymbol{\\Sigma} \\mathbf{v} = E_{\\mathbf{x} \\sim P}\\left[\\mathbf{v}^\\top(\\mathbf{x} - \\boldsymbol{\\mu}) (\\mathbf{x} - \\boldsymbol{\\mu})^\\top \\mathbf{v}\\right] = \\textrm{Var}_{x \\sim P}[\\mathbf{v}^\\top \\mathbf{x}].$$\n",
        "\n",
        "As such, $\\boldsymbol{\\Sigma}$ allows us to compute the variance\n",
        "for any linear function of $\\mathbf{x}$\n",
        "by a simple matrix multiplication.\n",
        "The off-diagonal elements tell us how correlated the coordinates are:\n",
        "a value of 0 means no correlation,\n",
        "where a larger positive value\n",
        "means that they are more strongly correlated.\n",
        "\n",
        "\n",
        "\n",
        "## Discussion\n",
        "\n",
        "In machine learning, there are many things to be uncertain about!\n",
        "We can be uncertain about the value of a label given an input.\n",
        "We can be uncertain about the estimated value of a parameter.\n",
        "We can even be uncertain about whether data arriving at deployment\n",
        "is even from the same distribution as the training data.\n",
        "\n",
        "By *aleatoric uncertainty*, we mean uncertainty\n",
        "that is intrinsic to the problem,\n",
        "and due to genuine randomness\n",
        "unaccounted for by the observed variables.\n",
        "By *epistemic uncertainty*, we mean uncertainty\n",
        "over a model's parameters, the sort of uncertainty\n",
        "that we can hope to reduce by collecting more data.\n",
        "We might have epistemic uncertainty\n",
        "concerning the probability\n",
        "that a coin turns up heads,\n",
        "but even once we know this probability,\n",
        "we are left with aleatoric uncertainty\n",
        "about the outcome of any future toss.\n",
        "No matter how long we watch someone tossing a fair coin,\n",
        "we will never be more or less than 50% certain\n",
        "that the next toss will come up heads.\n",
        "These terms come from mechanical modeling,\n",
        "(see e.g., :citet:`Der-Kiureghian.Ditlevsen.2009` for a review on this aspect of [uncertainty quantification](https://en.wikipedia.org/wiki/Uncertainty_quantification)).\n",
        "It is worth noting, however, that these terms constitute a slight abuse of language.\n",
        "The term *epistemic* refers to anything concerning *knowledge*\n",
        "and thus, in the philosophical sense, all uncertainty is epistemic.\n",
        "\n",
        "\n",
        "We saw that sampling data from some unknown probability distribution\n",
        "can provide us with information that can be used to estimate\n",
        "the parameters of the data generating distribution.\n",
        "That said, the rate at which this is possible can be quite slow.\n",
        "In our coin tossing example (and many others)\n",
        "we can do no better than to design estimators\n",
        "that converge at a rate of $1/\\sqrt{n}$,\n",
        "where $n$ is the sample size (e.g., the number of tosses).\n",
        "This means that by going from 10 to 1000 observations (usually a very achievable task)\n",
        "we see a tenfold reduction of uncertainty,\n",
        "whereas the next 1000 observations help comparatively little,\n",
        "offering only a 1.41 times reduction.\n",
        "This is a persistent feature of machine learning:\n",
        "while there are often easy gains, it takes a very large amount of data,\n",
        "and often with it an enormous amount of computation, to make further gains.\n",
        "For an empirical review of this fact for large scale language models see :citet:`Revels.Lubin.Papamarkou.2016`.\n",
        "\n",
        "We also sharpened our language and tools for statistical modeling.\n",
        "In the process of that we learned about conditional probabilities\n",
        "and about one of the most important equations in statistics---Bayes' theorem.\n",
        "It is an effective tool for decoupling information conveyed by data\n",
        "through a likelihood term $P(B \\mid A)$ that addresses\n",
        "how well observations $B$ match a choice of parameters $A$,\n",
        "and a prior probability $P(A)$ which governs how plausible\n",
        "a particular choice of $A$ was in the first place.\n",
        "In particular, we saw how this rule can be applied\n",
        "to assign probabilities to diagnoses,\n",
        "based on the efficacy of the test *and*\n",
        "the prevalence of the disease itself (i.e., our prior).\n",
        "\n",
        "Lastly, we introduced a first set of nontrivial questions\n",
        "about the effect of a specific probability distribution,\n",
        "namely expectations and variances.\n",
        "While there are many more than just linear and quadratic\n",
        "expectations for a probability distribution,\n",
        "these two already provide a good deal of knowledge\n",
        "about the possible behavior of the distribution.\n",
        "For instance, [Chebyshev's inequality](https://en.wikipedia.org/wiki/Chebyshev%27s_inequality)\n",
        "states that $P(|X - \\mu| \\geq k \\sigma) \\leq 1/k^2$,\n",
        "where $\\mu$ is the expectation, $\\sigma^2$ is the variance of the distribution,\n",
        "and $k > 1$ is a confidence parameter of our choosing.\n",
        "It tells us that draws from a distribution lie\n",
        "with at least 50% probability\n",
        "within a $[-\\sqrt{2} \\sigma, \\sqrt{2} \\sigma]$\n",
        "interval centered on the expectation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "1. Give an example where observing more data can reduce the amount of uncertainty about the outcome to an arbitrarily low level.\n",
        "1. Give an example where observing more data will only reduce the amount of uncertainty up to a point and then no further. Explain why this is the case and where you expect this point to occur.\n",
        "1. We empirically demonstrated convergence to the mean for the toss of a coin. Calculate the variance of the estimate of the probability that we see a head after drawing $n$ samples.\n",
        "    1. How does the variance scale with the number of observations?\n",
        "    1. Use Chebyshev's inequality to bound the deviation from the expectation.\n",
        "    1. How does it relate to the central limit theorem?\n",
        "1. Assume that we draw $m$ samples $x_i$ from a probability distribution with zero mean and unit variance. Compute the averages $z_m \\stackrel{\\textrm{def}}{=} m^{-1} \\sum_{i=1}^m x_i$. Can we apply Chebyshev's inequality for every $z_m$ independently? Why not?\n",
        "1. Given two events with probability $P(\\mathcal{A})$ and $P(\\mathcal{B})$, compute upper and lower bounds on $P(\\mathcal{A} \\cup \\mathcal{B})$ and $P(\\mathcal{A} \\cap \\mathcal{B})$. Hint: graph the situation using a [Venn diagram](https://en.wikipedia.org/wiki/Venn_diagram).\n",
        "1. Assume that we have a sequence of random variables, say $A$, $B$, and $C$, where $B$ only depends on $A$, and $C$ only depends on $B$, can you simplify the joint probability $P(A, B, C)$? Hint: this is a [Markov chain](https://en.wikipedia.org/wiki/Markov_chain).\n",
        "1. In :numref:`subsec_probability_hiv_app`, assume that the outcomes of the two tests are not independent. In particular assume that either test on its own has a false positive rate of 10% and a false negative rate of 1%. That is, assume that $P(D =1 \\mid H=0) = 0.1$ and that $P(D = 0 \\mid H=1) = 0.01$. Moreover, assume that for $H = 1$ (infected) the test outcomes are conditionally independent, i.e., that $P(D_1, D_2 \\mid H=1) = P(D_1 \\mid H=1) P(D_2 \\mid H=1)$ but that for healthy patients the outcomes are coupled via $P(D_1 = D_2 = 1 \\mid H=0) = 0.02$.\n",
        "    1. Work out the joint probability table for $D_1$ and $D_2$, given $H=0$ based on the information you have so far.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after one test returns positive. You can assume the same baseline probability $P(H=1) = 0.0015$ as before.\n",
        "    1. Derive the probability that the patient is diseased ($H=1$) after both tests return positive.\n",
        "1. Assume that you are an asset manager for an investment bank and you have a choice of stocks $s_i$ to invest in. Your portfolio needs to add up to $1$ with weights $\\alpha_i$ for each stock. The stocks have an average return $\\boldsymbol{\\mu} = E_{\\mathbf{s} \\sim P}[\\mathbf{s}]$ and covariance $\\boldsymbol{\\Sigma} = \\textrm{Cov}_{\\mathbf{s} \\sim P}[\\mathbf{s}]$.\n",
        "    1. Compute the expected return for a given portfolio $\\boldsymbol{\\alpha}$.\n",
        "    1. If you wanted to maximize the return of the portfolio, how should you choose your investment?\n",
        "    1. Compute the *variance* of the portfolio.\n",
        "    1. Formulate an optimization problem of maximizing the return while keeping the variance constrained to an upper bound. This is the Nobel-Prize winning [Markovitz portfolio](https://en.wikipedia.org/wiki/Markowitz_model) :cite:`Mangram.2013`. To solve it you will need a quadratic programming solver, something way beyond the scope of this book.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Two random variables  A  and  B  are conditionally independent given a third variable  C  if and only if  P(A,B∣C)=P(A∣C)P(B∣C) .+"
      ],
      "metadata": {
        "id": "EW63DI4ZCE5c"
      },
      "id": "EW63DI4ZCE5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "126c2b93",
      "metadata": {
        "origin_pos": 31,
        "tab": [
          "pytorch"
        ],
        "id": "126c2b93"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/37)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SkmxguGND4RO"
      },
      "id": "SkmxguGND4RO"
    },
    {
      "cell_type": "code",
      "source": [
        "#Given expected value 0.5⋅0+0.4⋅2+0.1⋅10=1.8\n",
        "#The variance of this expected value is 0.5⋅0+0.4⋅22+0.1⋅102−1.82=8.36\n",
        "#which is a large standard deviation from the expected value"
      ],
      "metadata": {
        "id": "SMsX0zZiD4qk"
      },
      "id": "SMsX0zZiD4qk",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}